# ğŸ¨ RAG Visual Guide - Before & After

---

## ğŸ“Š Current vs RAG: Side-by-Side

### Before RAG (Current System)

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  USER UPLOADS PDF (100 pages = 50K tokens)              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                  â”‚
                  â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  GEMINI EXTRACTS ALL TEXT                               â”‚
â”‚  âœ“ Extracto completo guardado                           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                  â”‚
                  â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  STORED IN FIRESTORE                                    â”‚
â”‚  context_sources.extractedData = "50,000 tokens"        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                  â”‚
                  â–¼
         USER ASKS: "Â¿QuÃ© dice sobre X?"
                  â”‚
                  â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  SEND ENTIRE 50K TOKENS TO GEMINI âŒ                    â”‚
â”‚                                                         â”‚
â”‚  Context Window:                                        â”‚
â”‚  â”œâ”€ System: 500 tokens                                 â”‚
â”‚  â”œâ”€ History: 2,000 tokens                              â”‚
â”‚  â”œâ”€ Documents: 50,000 tokens â† INEFICIENTE             â”‚
â”‚  â””â”€ User query: 20 tokens                              â”‚
â”‚                                                         â”‚
â”‚  Total: 52,520 tokens (5.2% of 1M window)              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                  â”‚
                  â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  GEMINI PROCESSES 52K TOKENS                            â”‚
â”‚  Cost (Flash): 52K Ã— $0.075/1M = $0.0039 per query     â”‚
â”‚  Cost (Pro): 52K Ã— $1.25/1M = $0.065 per query         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Problems:**
- ğŸ”´ Sending irrelevant information (95% of document not needed)
- ğŸ”´ Slow responses (more to process)
- ğŸ”´ Expensive (paying to process unused context)
- ğŸ”´ Limited scalability (can't add many documents)

---

### After RAG (Optimized System)

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  USER UPLOADS PDF (100 pages = 50K tokens)              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                  â”‚
                  â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  GEMINI EXTRACTS ALL TEXT                               â”‚
â”‚  âœ“ Extracto completo guardado                           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                  â”‚
                  â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  NEW: CHUNKING + EMBEDDINGS                             â”‚
â”‚  â”œâ”€ Split into 100 chunks (500 tokens each)            â”‚
â”‚  â”œâ”€ Generate 768-dim vector for each chunk             â”‚
â”‚  â””â”€ Store: chunks + embeddings in Firestore            â”‚
â”‚                                                         â”‚
â”‚  document_chunks collection:                            â”‚
â”‚  â”œâ”€ Chunk 0: "PÃ¡gina 1-2..." + [0.123, 0.456, ...]    â”‚
â”‚  â”œâ”€ Chunk 1: "PÃ¡gina 3-4..." + [0.789, 0.234, ...]    â”‚
â”‚  â””â”€ ... (100 chunks total)                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                  â”‚
                  â–¼
         USER ASKS: "Â¿QuÃ© dice sobre X?"
                  â”‚
                  â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  NEW: VECTOR SEARCH                                     â”‚
â”‚  1. Generate embedding for query                        â”‚
â”‚  2. Compare with all 100 chunk embeddings               â”‚
â”‚  3. Find top 5 most similar chunks                      â”‚
â”‚                                                         â”‚
â”‚  Results:                                               â”‚
â”‚  âœ“ Chunk 23 (similarity: 0.89) â† Highly relevant       â”‚
â”‚  âœ“ Chunk 45 (similarity: 0.84) â† Relevant              â”‚
â”‚  âœ“ Chunk 67 (similarity: 0.79) â† Relevant              â”‚
â”‚  âœ“ Chunk 12 (similarity: 0.71) â† Somewhat relevant     â”‚
â”‚  âœ“ Chunk 89 (similarity: 0.68) â† Somewhat relevant     â”‚
â”‚                                                         â”‚
â”‚  Total: 5 chunks Ã— 500 tokens = 2,500 tokens           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                  â”‚
                  â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  SEND ONLY RELEVANT 2.5K TOKENS TO GEMINI âœ…            â”‚
â”‚                                                         â”‚
â”‚  Context Window:                                        â”‚
â”‚  â”œâ”€ System: 500 tokens                                 â”‚
â”‚  â”œâ”€ History: 2,000 tokens                              â”‚
â”‚  â”œâ”€ Relevant chunks: 2,500 tokens â† EFICIENTE          â”‚
â”‚  â””â”€ User query: 20 tokens                              â”‚
â”‚                                                         â”‚
â”‚  Total: 5,020 tokens (0.5% of 1M window)               â”‚
â”‚  Savings: 90% reduction! ğŸ‰                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                  â”‚
                  â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  GEMINI PROCESSES 5K TOKENS (10x less)                  â”‚
â”‚  Cost (Flash): 5K Ã— $0.075/1M = $0.000375 per query    â”‚
â”‚  Cost (Pro): 5K Ã— $1.25/1M = $0.00625 per query        â”‚
â”‚                                                         â”‚
â”‚  Savings vs Before:                                     â”‚
â”‚  Flash: 10.4x cheaper                                   â”‚
â”‚  Pro: 10.4x cheaper                                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Benefits:**
- ğŸŸ¢ Only relevant information sent (better answers)
- ğŸŸ¢ Faster responses (less to process)
- ğŸŸ¢ Cheaper (10x+ cost reduction)
- ğŸŸ¢ Scalable (can add 10x more documents)

---

## ğŸ›ï¸ Configuration UI

### New Toggle in User Settings

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  ConfiguraciÃ³n de Usuario                           [X]â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                         â”‚
â”‚  Modelo Preferido                                       â”‚
â”‚  â—‹ Gemini 2.5 Flash                                    â”‚
â”‚  â— Gemini 2.5 Pro                                      â”‚
â”‚                                                         â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€    â”‚
â”‚                                                         â”‚
â”‚  ğŸ” BÃºsqueda Vectorial (RAG)              [Toggle ON]  â”‚
â”‚  Busca solo las partes relevantes de los documentos    â”‚
â”‚  en vez de enviar todo el contenido                     â”‚
â”‚                                                         â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”           â”‚
â”‚  â”‚ Eficiencia  â”‚  PrecisiÃ³n  â”‚  Velocidad  â”‚           â”‚
â”‚  â”‚ 40x menos   â”‚  Solo lo    â”‚  Respuestas â”‚           â”‚
â”‚  â”‚ tokens      â”‚  relevante  â”‚  mÃ¡s rÃ¡pidasâ”‚           â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜           â”‚
â”‚                                                         â”‚
â”‚  ConfiguraciÃ³n Avanzada:                                â”‚
â”‚  Chunks a recuperar: [5] â–¼                              â”‚
â”‚  TamaÃ±o de chunk: [500 tokens] â–¼                        â”‚
â”‚                                                         â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€    â”‚
â”‚                                                         â”‚
â”‚  Instrucciones del Sistema                              â”‚
â”‚  [textarea...]                                          â”‚
â”‚                                                         â”‚
â”‚                           [Guardar ConfiguraciÃ³n]      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ“ˆ Token Usage Comparison

### Example: 10 PDFs (1,000 pages total)

```
Current System:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 100 preguntas/mes                  â”‚
â”‚                                    â”‚
â”‚ Tokens por pregunta: 500,000      â”‚
â”‚ Total mensual: 50,000,000         â”‚
â”‚                                    â”‚
â”‚ Costo Flash: $3.75/mes            â”‚
â”‚ Costo Pro: $62.50/mes             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Con RAG:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 100 preguntas/mes                  â”‚
â”‚                                    â”‚
â”‚ Tokens por pregunta: 2,500 âœ¨     â”‚
â”‚ Total mensual: 250,000            â”‚
â”‚                                    â”‚
â”‚ Costo Flash: $0.02/mes ğŸ‰        â”‚
â”‚ Costo Pro: $0.31/mes ğŸ‰          â”‚
â”‚                                    â”‚
â”‚ Ahorro: 99.5%                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ” How RAG Search Works (Simplified)

### 1. Create Embeddings (One-Time per Document)

```
Document: "Las construcciones deben cumplir con normativa..."

Chunk 1: "Las construcciones deben cumplir..."
    â†“
Vertex AI Embeddings
    â†“
Vector: [0.123, 0.456, 0.789, ..., 0.234]  (768 numbers)
         â””â”€ Mathematical representation of meaning
```

### 2. Search (Every Query)

```
User Query: "Â¿CuÃ¡les son los requisitos de construcciÃ³n?"
    â†“
Vertex AI Embeddings
    â†“
Query Vector: [0.145, 0.432, 0.801, ..., 0.267]

Compare with all chunks:
â”œâ”€ Chunk 1: similarity = 0.89 â† HIGH! Include this
â”œâ”€ Chunk 2: similarity = 0.34 â† Low, skip
â”œâ”€ Chunk 3: similarity = 0.82 â† HIGH! Include this
â””â”€ ... 

Top 5 chunks selected â†’ Send to Gemini
```

### 3. Similarity Explained

```
Vector similarity measures "meaning closeness":

Query: "requisitos de construcciÃ³n"
Chunk: "Las construcciones deben cumplir con..."
    â†“
Similarity: 0.89 (89% similar in meaning)
    â†“
Result: VERY RELEVANT âœ…

Query: "requisitos de construcciÃ³n"
Chunk: "El autor agradece a su familia..."
    â†“
Similarity: 0.12 (12% similar)
    â†“
Result: NOT RELEVANT âŒ
```

**Magic:** Works across languages, synonyms, and paraphrasing!

---

## ğŸ¨ Visual Indicators in UI

### Context Panel (When RAG Active)

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Desglose del Contexto                          0.5% âœ¨ â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                         â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚ ğŸ” BÃºsqueda Vectorial Activa                     â”‚   â”‚
â”‚  â”‚                                                  â”‚   â”‚
â”‚  â”‚ Se encontraron 5 fragmentos relevantes de       â”‚   â”‚
â”‚  â”‚ 234 disponibles.                                â”‚   â”‚
â”‚  â”‚                                                  â”‚   â”‚
â”‚  â”‚ Ahorro: 95.2% de tokens                         â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                                         â”‚
â”‚  Fuentes de Contexto (RAG)                              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚ ğŸ“„ Normativa OGUC.pdf                            â”‚   â”‚
â”‚  â”‚ âœ“ 3 fragmentos (relevancia: 89%, 84%, 79%)      â”‚   â”‚
â”‚  â”‚ Chunks: 23, 45, 67 de 89 totales                â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                                         â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚ ğŸ“„ Manual ConstrucciÃ³n.pdf                       â”‚   â”‚
â”‚  â”‚ âœ“ 2 fragmentos (relevancia: 82%, 71%)           â”‚   â”‚
â”‚  â”‚ Chunks: 12, 34 de 156 totales                   â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Context Logs Table (New Column)

```
â”Œâ”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ #  â”‚ Hora     â”‚ Modelo â”‚ Input â”‚ Output â”‚ Total â”‚ Disponib â”‚  Uso%  â”‚   RAG   â”‚
â”œâ”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ 1  â”‚ 14:32:15 â”‚ Flash  â”‚ 52.5K â”‚  487   â”‚ 53K   â”‚  947K    â”‚  5.3%  â”‚   -     â”‚ â† Sin RAG
â”‚ 2  â”‚ 14:35:22 â”‚ Flash  â”‚  2.8K â”‚  523   â”‚  3.3K â”‚  996.7K  â”‚  0.3%  â”‚ âœ“ 5 ch  â”‚ â† Con RAG
â”‚ 3  â”‚ 14:38:45 â”‚ Pro    â”‚  3.1K â”‚  612   â”‚  3.7K â”‚ 1,996K   â”‚  0.2%  â”‚ âœ“ 5 ch  â”‚ â† Con RAG
â””â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                                                         â†‘
                                                        Nuevo: Indica RAG usado
                                                        y cuÃ¡ntos chunks
```

---

## ğŸ’¾ Firestore Data Structure

### New Collection: document_chunks

```
context_sources/abc123                â† Document
    â†“
    â”œâ”€ name: "Normativa OGUC.pdf"
    â”œâ”€ extractedData: "Full text..."
    â”œâ”€ ragEnabled: true
    â””â”€ ragMetadata: {
          totalChunks: 89,
          embeddingModel: "text-embedding-004",
          indexedAt: 2025-10-18T14:30:00Z
       }

document_chunks/chunk001              â† Chunk 0
    â”œâ”€ sourceId: "abc123"
    â”œâ”€ userId: "user-xyz"
    â”œâ”€ chunkIndex: 0
    â”œâ”€ text: "Las construcciones deben cumplir..."
    â”œâ”€ embedding: [0.123, 0.456, ..., 0.789] (768 numbers)
    â””â”€ metadata: {
          startChar: 0,
          endChar: 2000,
          tokenCount: 500
       }

document_chunks/chunk002              â† Chunk 1
    â”œâ”€ sourceId: "abc123"
    â”œâ”€ chunkIndex: 1
    â”œâ”€ text: "Los distanciamientos mÃ­nimos..."
    â”œâ”€ embedding: [0.234, 0.567, ..., 0.890]
    â””â”€ ...

... (89 chunks total)
```

**Storage:**
- Text: ~500 chars per chunk
- Embedding: 768 floats Ã— 4 bytes = 3KB per chunk
- Total per chunk: ~3.5KB
- 1,000 chunks = 3.5MB (cheap in Firestore)

---

## ğŸ”„ Processing Flow Diagram

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    DOCUMENT UPLOAD FLOW                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

  User Selects PDF
        â”‚
        â–¼
  Frontend â†’ API (/api/extract-document)
        â”‚
        â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚                                         â”‚
        â–¼                                         â–¼
  Save to Cloud Storage              Extract with Gemini
  (original file)                    (get full text)
        â”‚                                         â”‚
        â”‚                                         â–¼
        â”‚                              NEW: Chunk Text
        â”‚                              (500 tokens each)
        â”‚                                         â”‚
        â”‚                                         â–¼
        â”‚                              NEW: Generate Embeddings
        â”‚                              (Vertex AI)
        â”‚                                         â”‚
        â”‚                                         â–¼
        â”‚                              NEW: Store Chunks + Embeddings
        â”‚                              (document_chunks collection)
        â”‚                                         â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                          â–¼
                Save Metadata
          (context_sources with ragMetadata)
                          â”‚
                          â–¼
                   Show in UI
              "âœ“ Indexed for RAG"
```

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    QUESTION ANSWERING FLOW                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

  User Asks Question
        â”‚
        â–¼
  Frontend â†’ API (/api/conversations/:id/messages)
        â”‚
        â–¼
  NEW: RAG Search
  â”œâ”€ Generate query embedding
  â”œâ”€ Load user's chunks from Firestore
  â”œâ”€ Calculate similarities
  â””â”€ Select top 5 chunks
        â”‚
        â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚                â”‚                 â”‚
        â–¼                â–¼                 â–¼
  Chunk 23         Chunk 45          Chunk 67
  (0.89 similar)   (0.84 similar)    (0.79 similar)
        â”‚                â”‚                 â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                  â”‚
                                  â–¼
                        Build Context String
                     (only these 5 chunks)
                                  â”‚
                                  â–¼
                           Send to Gemini
                     (with conversation history)
                                  â”‚
                                  â–¼
                         Get AI Response
                                  â”‚
                                  â–¼
                    Save to Firestore + Return
```

---

## ğŸ“± User Experience Changes

### Upload Experience

**Before:**
```
Upload PDF
    â†“
â³ Processing... (30 seconds)
    â†“
âœ“ Extracted 50K tokens
    â†“
Ready to use
```

**After:**
```
Upload PDF
    â†“
â³ Processing... (30 seconds)
    â†“
âœ“ Extracted 50K tokens
    â†“
ğŸ” Indexing for search... (10 seconds)  â† NEW
    â†“
Progress: â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘ 75%          â† NEW
Creating 100 chunks...
Generating embeddings...
    â†“
âœ“ Indexed for RAG (100 chunks)          â† NEW
    â†“
Ready to use with optimized search âœ¨
```

### Query Experience

**Before:**
```
User: "Â¿QuÃ© dice sobre construcciones?"
    â†“
â³ Thinking... (5 seconds)
    â†“
Response: [Answer using entire document]
```

**After:**
```
User: "Â¿QuÃ© dice sobre construcciones?"
    â†“
ğŸ” Searching... (0.3 seconds)            â† NEW (visible)
Found 5 relevant sections
    â†“
â³ Thinking... (2 seconds)               â† FASTER
    â†“
Response: [Answer using only relevant parts]

Con referencias:
"SegÃºn el documento[1], las construcciones..."

[1] Normativa OGUC.pdf, Chunk 23 (relevancia: 89%)
    â†“
    Clickable â†’ Shows exact chunk used
```

---

## ğŸ¯ Smart Fallback System

RAG can fail gracefully:

```
User asks question
    â”‚
    â”œâ”€ Try RAG search
    â”‚       â”‚
    â”‚       â”œâ”€ Success? â†’ Use relevant chunks âœ…
    â”‚       â”‚
    â”‚       â””â”€ Failed/No results?
    â”‚               â”‚
    â”‚               â””â”€ Fall back to full documents âœ…
    â”‚
    â””â”€ RAG disabled?
            â”‚
            â””â”€ Use full documents âœ…
```

**Result:** Always works, best effort optimization

---

## ğŸ“Š Performance Comparison

### Latency

```
Current System (Full Document):
â”œâ”€ Load documents: 200ms
â”œâ”€ Build context: 50ms
â”œâ”€ Gemini API: 4,000ms (large context)
â””â”€ Total: ~4.25 seconds

With RAG:
â”œâ”€ Generate query embedding: 100ms
â”œâ”€ Search chunks: 200ms
â”œâ”€ Build context: 20ms (5 chunks vs full doc)
â”œâ”€ Gemini API: 1,500ms (small context)
â””â”€ Total: ~1.82 seconds

Improvement: 2.3x faster âš¡
```

### Scalability

```
Current System:
â”œâ”€ 10 documents (1K pages): OK (uses 10% of context)
â”œâ”€ 50 documents (5K pages): Slow (uses 50% of context)
â””â”€ 100 documents (10K pages): Fails (exceeds 1M token limit) âŒ

With RAG:
â”œâ”€ 10 documents: Excellent (uses <1% of context)
â”œâ”€ 50 documents: Excellent (uses <1% of context)
â”œâ”€ 100 documents: Excellent (uses <1% of context)
â”œâ”€ 500 documents: Good (uses ~2% of context)
â””â”€ 1,000 documents: OK (uses ~5% of context) âœ…

Can support 100x more documents!
```

---

## ğŸ§ª Testing Scenarios

### Test 1: Quality Comparison

**Setup:**
1. Upload test document with RAG disabled
2. Ask 10 test questions, save responses
3. Enable RAG
4. Ask same 10 questions
5. Compare answers

**Expected:**
- âœ… Same or better answer quality
- âœ… More specific citations
- âœ… Faster responses

### Test 2: Large Document Library

**Setup:**
1. Upload 20 documents (2,000+ pages)
2. Try to use all with current system
3. Enable RAG
4. Compare performance

**Expected:**
- âŒ Current: Slow/fails with context overflow
- âœ… RAG: Fast, no issues

### Test 3: Irrelevant Document Handling

**Setup:**
1. Upload unrelated documents
2. Ask specific question
3. Check which chunks are retrieved

**Expected:**
- âœ… Only relevant chunks retrieved (low similarity â†’ excluded)
- âœ… Irrelevant docs don't pollute context

---

## ğŸ“ When to Use RAG vs Full Document

### Use RAG When:
- âœ… Documents > 10 pages each
- âœ… Multiple documents active
- âœ… Specific factual questions
- âœ… Need cost optimization
- âœ… Need faster responses

### Use Full Document When:
- âœ… Documents < 5 pages
- âœ… Single small document
- âœ… Need complete context (summaries, overviews)
- âœ… RAG indexing not complete yet

### Hybrid Approach (Best):
- âœ… User can toggle per document
- âœ… System auto-selects based on size
- âœ… Graceful fallback if RAG fails

---

## ğŸ“ˆ ROI Calculation

### Investment

**Development Time:** 4-6 hours
**Infrastructure:** $0 (uses existing GCP)
**Ongoing Costs:** 
- Embeddings: ~$0.01 per 1,000 chunks (one-time)
- Storage: ~$0.10/month per 1,000 chunks
- Search: Included in Gemini API cost

**Total:** ~$1-2 setup + $0.50/month per 1,000 documents

### Returns

**Monthly Savings** (based on 100 questions/month):

| Documents | Pages | Current Cost (Flash) | RAG Cost | Savings |
|-----------|-------|---------------------|----------|---------|
| 10        | 1,000 | $3.75               | $0.03    | $3.72   |
| 50        | 5,000 | $18.75              | $0.15    | $18.60  |
| 100       | 10K   | $37.50              | $0.30    | $37.20  |

**Break-even:** Month 1 (immediate savings) ğŸ‰

---

## ğŸš€ Next Steps

To implement RAG:

1. **Review this plan** - Make sure you understand the approach
2. **Approve architecture** - Confirm Vertex AI + Firestore approach
3. **Enable Vertex AI API** - One gcloud command
4. **Implement services** - 3 new files (~400 lines total)
5. **Update endpoints** - Modify 2 existing files
6. **Add UI toggle** - Update UserSettings modal
7. **Test thoroughly** - Compare quality and performance
8. **Deploy gradually** - Phase 1 (new uploads only)

**Estimated Timeline:** 1-2 days for complete implementation + testing

---

**Ready to start?** ğŸš€

Just say "yes" and I'll begin implementing the core RAG functionality!

