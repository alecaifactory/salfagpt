# ðŸ—ï¸ RAG Complementary Architecture - Complete Flow

**Date:** October 18, 2025  
**Principle:** RAG **extends** existing system, doesn't replace it

---

## ðŸŽ¯ Core Principle: Dual-Mode Operation

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    COMPLEMENTARY ARCHITECTURE                    â”‚
â”‚                                                                 â”‚
â”‚  Every document supports BOTH modes simultaneously:             â”‚
â”‚                                                                 â”‚
â”‚  Mode 1: Full-Text (ALWAYS available)                          â”‚
â”‚  Mode 2: RAG Search (OPTIONAL enhancement)                     â”‚
â”‚                                                                 â”‚
â”‚  System intelligently chooses best mode per query              â”‚
â”‚                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ðŸ“Š Complete Architecture - ASCII Diagram

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         1. UPLOAD & EXTRACTION                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

User uploads PDF
      â”‚
      â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  API: /api/extract-document                 â”‚
â”‚                                             â”‚
â”‚  Input:                                     â”‚
â”‚  â€¢ file: File (PDF)                         â”‚
â”‚  â€¢ userId: string                           â”‚
â”‚  â€¢ model: 'flash' | 'pro'                   â”‚
â”‚  â€¢ ragEnabled: boolean (optional)           â”‚
â”‚                                             â”‚
â”‚  Process:                                   â”‚
â”‚  â”œâ”€ Gemini Vision extraction (multimodal)  â”‚
â”‚  â”‚  â”œâ”€ Extract text                        â”‚
â”‚  â”‚  â”œâ”€ Describe images                     â”‚
â”‚  â”‚  â””â”€ Convert tables to text              â”‚
â”‚  â”‚                                          â”‚
â”‚  â”‚  Result: Rich extractedText (complete)  â”‚
â”‚  â”‚                                          â”‚
â”‚  â””â”€ Return to frontend                     â”‚
â”‚                                             â”‚
â”‚  Output:                                    â”‚
â”‚  {                                          â”‚
â”‚    success: true,                           â”‚
â”‚    extractedText: "Complete text...",       â”‚
â”‚    metadata: { ... }                        â”‚
â”‚  }                                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
      â”‚
      â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Frontend: ContextManagementDashboard       â”‚
â”‚                                             â”‚
â”‚  Receives extractedText                     â”‚
â”‚  Creates context_sources document:          â”‚
â”‚                                             â”‚
â”‚  {                                          â”‚
â”‚    id: "src_abc123",                        â”‚
â”‚    userId: "user_xyz",                      â”‚
â”‚    name: "Document.pdf",                    â”‚
â”‚    extractedData: "Complete text...",       â”‚ â† Full-text (ALWAYS)
â”‚    ragEnabled: false,  // Initially          â”‚
â”‚    status: "active"                         â”‚
â”‚  }                                          â”‚
â”‚                                             â”‚
â”‚  âœ… Document ready for full-text queries   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜


â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      2. RAG INDEXING (OPTIONAL)                            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

User or Admin enables RAG for document
      â”‚
      â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  API: /api/context-sources/:id/enable-rag   â”‚
â”‚                                             â”‚
â”‚  Input:                                     â”‚
â”‚  â€¢ sourceId: string                         â”‚
â”‚  â€¢ userId: string                           â”‚
â”‚  â€¢ chunkSize: number (default: 500)         â”‚
â”‚  â€¢ overlap: number (default: 50)            â”‚
â”‚                                             â”‚
â”‚  Process:                                   â”‚
â”‚  â”œâ”€ Load extractedData from Firestore      â”‚ â† Uses existing extraction
â”‚  â”‚                                          â”‚
â”‚  â”œâ”€ Chunk the text                         â”‚
â”‚  â”‚  â”œâ”€ Smart chunking (paragraph-aware)    â”‚
â”‚  â”‚  â”œâ”€ 500 tokens per chunk                â”‚
â”‚  â”‚  â””â”€ 50 tokens overlap                   â”‚
â”‚  â”‚                                          â”‚
â”‚  â”‚  Result: 100 chunks for 100-page doc    â”‚
â”‚  â”‚                                          â”‚
â”‚  â”œâ”€ Generate embeddings                    â”‚
â”‚  â”‚  â”œâ”€ For each chunk                      â”‚
â”‚  â”‚  â”œâ”€ 768-dimensional vectors             â”‚
â”‚  â”‚  â””â”€ Batch processing (5 at a time)      â”‚
â”‚  â”‚                                          â”‚
â”‚  â”‚  Result: 100 embeddings                 â”‚
â”‚  â”‚                                          â”‚
â”‚  â””â”€ Store in Firestore                     â”‚
â”‚                                             â”‚
â”‚  Output:                                    â”‚
â”‚  {                                          â”‚
â”‚    success: true,                           â”‚
â”‚    chunksCreated: 100,                      â”‚
â”‚    totalTokens: 50000                       â”‚
â”‚  }                                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
      â”‚
      â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Firestore: TWO complementary stores        â”‚
â”‚                                             â”‚
â”‚  Collection: context_sources                â”‚
â”‚  Document: src_abc123                       â”‚
â”‚  {                                          â”‚
â”‚    extractedData: "Full text...",           â”‚ â† Mode 1: Full-text
â”‚    ragEnabled: true,                        â”‚ â† RAG now available
â”‚    ragMetadata: {                           â”‚
â”‚      totalChunks: 100,                      â”‚
â”‚      indexedAt: "2025-10-18"                â”‚
â”‚    }                                        â”‚
â”‚  }                                          â”‚
â”‚                                             â”‚
â”‚  Collection: document_chunks                â”‚ â† Mode 2: RAG chunks
â”‚  Documents: chunk_001, chunk_002, ...       â”‚
â”‚  {                                          â”‚
â”‚    sourceId: "src_abc123",                  â”‚ â† Links to full doc
â”‚    chunkIndex: 0,                           â”‚
â”‚    text: "Chunk text with complete info",  â”‚
â”‚    embedding: [0.123, 0.456, ..., 0.789]   â”‚
â”‚  }                                          â”‚
â”‚                                             â”‚
â”‚  âœ… Both modes available simultaneously     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜


â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         3. Q&A WITH AGENT                                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

User asks question in agent
      â”‚
      â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  API: /api/conversations/:id/messages                                    â”‚
â”‚                                                                          â”‚
â”‚  Input:                                                                  â”‚
â”‚  â€¢ conversationId: string                                                â”‚
â”‚  â€¢ userId: string                                                        â”‚
â”‚  â€¢ message: "What were Q4 sales?"                                        â”‚
â”‚  â€¢ contextSources: [{ id, name, content }]                               â”‚
â”‚  â€¢ ragEnabled: boolean (from user settings)                              â”‚
â”‚                                                                          â”‚
â”‚  Decision Tree:                                                          â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”       â”‚
â”‚  â”‚                                                              â”‚       â”‚
â”‚  â”‚  Is RAG enabled? â”€â”€Noâ”€â”€â†’ Use Full-Text Mode â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚       â”‚
â”‚  â”‚       â”‚                   (Mode 1: Original behavior)     â”‚  â”‚       â”‚
â”‚  â”‚      Yes                                                  â”‚  â”‚       â”‚
â”‚  â”‚       â”‚                                                   â”‚  â”‚       â”‚
â”‚  â”‚       â–¼                                                   â”‚  â”‚       â”‚
â”‚  â”‚  Do chunks exist? â”€â”€Noâ”€â”€â†’ Use Full-Text Mode â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤  â”‚       â”‚
â”‚  â”‚       â”‚                   (Graceful fallback)            â”‚  â”‚       â”‚
â”‚  â”‚      Yes                                                  â”‚  â”‚       â”‚
â”‚  â”‚       â”‚                                                   â”‚  â”‚       â”‚
â”‚  â”‚       â–¼                                                   â”‚  â”‚       â”‚
â”‚  â”‚  Try RAG Search                                           â”‚  â”‚       â”‚
â”‚  â”‚       â”‚                                                   â”‚  â”‚       â”‚
â”‚  â”‚   Success?â”€â”€Noâ”€â”€â†’ Use Full-Text Mode â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤  â”‚       â”‚
â”‚  â”‚       â”‚            (Graceful fallback)                   â”‚  â”‚       â”‚
â”‚  â”‚      Yes                                                  â”‚  â”‚       â”‚
â”‚  â”‚       â”‚                                                   â”‚  â”‚       â”‚
â”‚  â”‚       â–¼                                                   â”‚  â”‚       â”‚
â”‚  â”‚  Results above                                            â”‚  â”‚       â”‚
â”‚  â”‚  threshold?â”€â”€Noâ”€â”€â†’ Use Full-Text Mode â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤  â”‚       â”‚
â”‚  â”‚       â”‚             (Quality check)                      â”‚  â”‚       â”‚
â”‚  â”‚      Yes                                                  â”‚  â”‚       â”‚
â”‚  â”‚       â”‚                                                   â”‚  â”‚       â”‚
â”‚  â”‚       â–¼                                                   â”‚  â”‚       â”‚
â”‚  â”‚  Use RAG Results â—„â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚       â”‚
â”‚  â”‚  (Mode 2: Optimized)                                         â”‚       â”‚
â”‚  â”‚                                                              â”‚       â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜       â”‚
â”‚                                                                          â”‚
â”‚  Mode 1: Full-Text                    Mode 2: RAG Search                 â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€               â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”             â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”          â”‚
â”‚  â”‚ Load full document:  â”‚             â”‚ RAG Search:          â”‚          â”‚
â”‚  â”‚                      â”‚             â”‚                      â”‚          â”‚
â”‚  â”‚ additionalContext =  â”‚             â”‚ 1. Generate query    â”‚          â”‚
â”‚  â”‚   contextSources     â”‚             â”‚    embedding         â”‚          â”‚
â”‚  â”‚   .map(s =>          â”‚             â”‚                      â”‚          â”‚
â”‚  â”‚     `=== ${s.name}   â”‚             â”‚ 2. Search chunks     â”‚          â”‚
â”‚  â”‚      ===\n           â”‚             â”‚    (cosine simil.)   â”‚          â”‚
â”‚  â”‚      ${s.content}`)  â”‚             â”‚                      â”‚          â”‚
â”‚  â”‚   .join('\n');       â”‚             â”‚ 3. Get top 5 chunks  â”‚          â”‚
â”‚  â”‚                      â”‚             â”‚                      â”‚          â”‚
â”‚  â”‚ Tokens: 50,000       â”‚             â”‚ 4. Build context:    â”‚          â”‚
â”‚  â”‚ (full document)      â”‚             â”‚    additionalContext â”‚          â”‚
â”‚  â”‚                      â”‚             â”‚    = buildRAGContext â”‚          â”‚
â”‚  â”‚                      â”‚             â”‚      (ragResults)    â”‚          â”‚
â”‚  â”‚                      â”‚             â”‚                      â”‚          â”‚
â”‚  â”‚                      â”‚             â”‚ Tokens: 2,500        â”‚          â”‚
â”‚  â”‚                      â”‚             â”‚ (relevant chunks)    â”‚          â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜             â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜          â”‚
â”‚           â”‚                                     â”‚                        â”‚
â”‚           â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                        â”‚
â”‚                          â–¼                                               â”‚
â”‚                  Send to Gemini AI                                       â”‚
â”‚                  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                    â”‚
â”‚                  â”‚ System prompt    â”‚                                    â”‚
â”‚                  â”‚ History          â”‚                                    â”‚
â”‚                  â”‚ Context â—„â”€â”€â”€â”€â”€â”€â”€â”€â”¤ From Mode 1 or Mode 2             â”‚
â”‚                  â”‚ User query       â”‚                                    â”‚
â”‚                  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                    â”‚
â”‚                          â”‚                                               â”‚
â”‚                          â–¼                                               â”‚
â”‚                   AI Response                                            â”‚
â”‚                                                                          â”‚
â”‚  Output:                                                                 â”‚
â”‚  {                                                                       â”‚
â”‚    message: { role: 'assistant', content: "..." },                       â”‚
â”‚    ragStats: { chunks: 5, tokens: 2500, ... } or null,                   â”‚
â”‚    tokenStats: { input, output, ... }                                    â”‚
â”‚  }                                                                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ðŸ”„ Complete Flow - Step by Step

### STEP 1: Upload & Extraction (âœ… Working Now)

```
User Action: Upload PDF
      â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Frontend: ContextManagementDashboard.tsx                     â”‚
â”‚  Method: handleSubmitUpload()                                 â”‚
â”‚                                                               â”‚
â”‚  const formData = new FormData();                             â”‚
â”‚  formData.append('file', pdfFile);                            â”‚
â”‚  formData.append('userId', userId);                           â”‚
â”‚  formData.append('model', 'gemini-2.5-flash');                â”‚
â”‚                                                               â”‚
â”‚  fetch('/api/extract-document', {                             â”‚
â”‚    method: 'POST',                                            â”‚
â”‚    body: formData                                             â”‚
â”‚  })                                                           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
      â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Backend: /api/extract-document                               â”‚
â”‚  File: src/pages/api/extract-document.ts                      â”‚
â”‚                                                               â”‚
â”‚  1. Receive PDF file                                          â”‚
â”‚  2. Convert to base64                                         â”‚
â”‚  3. Call Gemini Vision:                                       â”‚
â”‚                                                               â”‚
â”‚     genAI.models.generateContent({                            â”‚
â”‚       model: 'gemini-2.5-flash',                              â”‚
â”‚       contents: [{                                            â”‚
â”‚         role: 'user',                                         â”‚
â”‚         parts: [{                                             â”‚
â”‚           inlineData: {                                       â”‚
â”‚             mimeType: 'application/pdf',                      â”‚
â”‚             data: base64Data                                  â”‚
â”‚           }                                                   â”‚
â”‚         }, {                                                  â”‚
â”‚           text: 'Extract all text, describe images...'        â”‚
â”‚         }]                                                    â”‚
â”‚       }]                                                      â”‚
â”‚     })                                                        â”‚
â”‚                                                               â”‚
â”‚  4. Get extractedText (rich multimodal text)                  â”‚
â”‚  5. Return to frontend                                        â”‚
â”‚                                                               â”‚
â”‚  Output:                                                      â”‚
â”‚  {                                                            â”‚
â”‚    success: true,                                             â”‚
â”‚    extractedText: "Page 1: Sales data...\n                    â”‚
â”‚                    [Image: Bar chart Q1-Q4]\n                 â”‚
â”‚                    Table: Revenue breakdown...",              â”‚
â”‚    metadata: {                                                â”‚
â”‚      characters: 48234,                                       â”‚
â”‚      extractionTime: 8234,                                    â”‚
â”‚      model: 'gemini-2.5-flash'                                â”‚
â”‚    }                                                          â”‚
â”‚  }                                                            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
      â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Frontend: ContextManagementDashboard.tsx                     â”‚
â”‚  Method: processQueue() continuation                          â”‚
â”‚                                                               â”‚
â”‚  fetch('/api/context-sources', {                              â”‚
â”‚    method: 'POST',                                            â”‚
â”‚    body: JSON.stringify({                                     â”‚
â”‚      userId,                                                  â”‚
â”‚      name: 'Document.pdf',                                    â”‚
â”‚      type: 'pdf',                                             â”‚
â”‚      extractedData: uploadData.extractedText,  â† STORED      â”‚
â”‚      metadata: { ... }                                        â”‚
â”‚    })                                                         â”‚
â”‚  })                                                           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
      â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Firestore: context_sources collection                        â”‚
â”‚                                                               â”‚
â”‚  Document created: src_abc123                                 â”‚
â”‚  {                                                            â”‚
â”‚    id: "src_abc123",                                          â”‚
â”‚    userId: "user_xyz",                                        â”‚
â”‚    name: "Document.pdf",                                      â”‚
â”‚    type: "pdf",                                               â”‚
â”‚    extractedData: "Complete multimodal text...",  â† 50K tokensâ”‚
â”‚    ragEnabled: false,         â† RAG not yet enabled           â”‚
â”‚    status: "active",                                          â”‚
â”‚    metadata: { ... }                                          â”‚
â”‚  }                                                            â”‚
â”‚                                                               â”‚
â”‚  âœ… Document usable immediately (full-text mode)              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜


â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    2. RAG INDEXING (NEW - OPTIONAL)                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Admin or User enables RAG for document
      â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Option A: User Settings (Global)                             â”‚
â”‚                                                               â”‚
â”‚  User clicks Settings â†’ Toggle RAG ON                         â”‚
â”‚  Applies to all future queries                                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Option B: Admin Panel (System-wide)                          â”‚
â”‚                                                               â”‚
â”‚  Admin clicks "ConfiguraciÃ³n RAG" â†’ Enable RAG                â”‚
â”‚  Applies to all users, all documents                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Option C: Per-Document (Future)                              â”‚
â”‚                                                               â”‚
â”‚  Context source settings â†’ Enable RAG for this doc            â”‚
â”‚  Click "Index for RAG" button                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

      â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  API: /api/context-sources/:id/enable-rag (NEW)               â”‚
â”‚  File: src/pages/api/context-sources/[id]/enable-rag.ts       â”‚
â”‚                                                               â”‚
â”‚  Input:                                                       â”‚
â”‚  â€¢ sourceId: "src_abc123"                                     â”‚
â”‚  â€¢ userId: "user_xyz"                                         â”‚
â”‚  â€¢ chunkSize: 500  (optional)                                 â”‚
â”‚  â€¢ overlap: 50     (optional)                                 â”‚
â”‚                                                               â”‚
â”‚  Process:                                                     â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”           â”‚
â”‚  â”‚ 1. Load source from Firestore                  â”‚           â”‚
â”‚  â”‚    const source = await getContextSource(id)   â”‚           â”‚
â”‚  â”‚    const fullText = source.extractedData       â”‚ â† Reuse   â”‚
â”‚  â”‚                                                â”‚           â”‚
â”‚  â”‚ 2. Chunk the extracted text                    â”‚           â”‚
â”‚  â”‚    import { chunkTextSmart } from '../../lib/chunking'     â”‚
â”‚  â”‚                                                â”‚           â”‚
â”‚  â”‚    const chunks = chunkTextSmart(fullText, 500)â”‚           â”‚
â”‚  â”‚    // Result: 100 chunks                       â”‚           â”‚
â”‚  â”‚                                                â”‚           â”‚
â”‚  â”‚ 3. Generate embeddings for each chunk          â”‚           â”‚
â”‚  â”‚    import { generateEmbeddingsBatch }          â”‚           â”‚
â”‚  â”‚           from '../../lib/embeddings'          â”‚           â”‚
â”‚  â”‚                                                â”‚           â”‚
â”‚  â”‚    const chunkTexts = chunks.map(c => c.text)  â”‚           â”‚
â”‚  â”‚    const embeddings =                          â”‚           â”‚
â”‚  â”‚      await generateEmbeddingsBatch(chunkTexts) â”‚           â”‚
â”‚  â”‚    // Result: 100 vectors (768-dim each)       â”‚           â”‚
â”‚  â”‚                                                â”‚           â”‚
â”‚  â”‚ 4. Store chunks in Firestore                   â”‚           â”‚
â”‚  â”‚    const batch = firestore.batch();            â”‚           â”‚
â”‚  â”‚                                                â”‚           â”‚
â”‚  â”‚    chunks.forEach((chunk, i) => {              â”‚           â”‚
â”‚  â”‚      batch.set(                                â”‚           â”‚
â”‚  â”‚        firestore.collection('document_chunks') â”‚           â”‚
â”‚  â”‚          .doc(),                               â”‚           â”‚
â”‚  â”‚        {                                       â”‚           â”‚
â”‚  â”‚          sourceId: 'src_abc123',               â”‚           â”‚
â”‚  â”‚          userId: 'user_xyz',                   â”‚           â”‚
â”‚  â”‚          chunkIndex: i,                        â”‚           â”‚
â”‚  â”‚          text: chunk.text,                     â”‚           â”‚
â”‚  â”‚          embedding: embeddings[i],             â”‚           â”‚
â”‚  â”‚          metadata: {                           â”‚           â”‚
â”‚  â”‚            startChar: chunk.startChar,         â”‚           â”‚
â”‚  â”‚            endChar: chunk.endChar,             â”‚           â”‚
â”‚  â”‚            tokenCount: chunk.tokenCount        â”‚           â”‚
â”‚  â”‚          }                                     â”‚           â”‚
â”‚  â”‚        }                                       â”‚           â”‚
â”‚  â”‚      );                                        â”‚           â”‚
â”‚  â”‚    });                                         â”‚           â”‚
â”‚  â”‚                                                â”‚           â”‚
â”‚  â”‚    await batch.commit();                       â”‚           â”‚
â”‚  â”‚                                                â”‚           â”‚
â”‚  â”‚ 5. Update source document                      â”‚           â”‚
â”‚  â”‚    await firestore                             â”‚           â”‚
â”‚  â”‚      .collection('context_sources')            â”‚           â”‚
â”‚  â”‚      .doc('src_abc123')                        â”‚           â”‚
â”‚  â”‚      .update({                                 â”‚           â”‚
â”‚  â”‚        ragEnabled: true,                       â”‚           â”‚
â”‚  â”‚        ragMetadata: {                          â”‚           â”‚
â”‚  â”‚          totalChunks: 100,                     â”‚           â”‚
â”‚  â”‚          embeddingModel: 'text-embedding-004', â”‚           â”‚
â”‚  â”‚          chunkSize: 500,                       â”‚           â”‚
â”‚  â”‚          indexedAt: new Date()                 â”‚           â”‚
â”‚  â”‚        }                                       â”‚           â”‚
â”‚  â”‚      });                                       â”‚           â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜           â”‚
â”‚                                                               â”‚
â”‚  Output:                                                      â”‚
â”‚  {                                                            â”‚
â”‚    success: true,                                             â”‚
â”‚    chunksCreated: 100,                                        â”‚
â”‚    message: "Document indexed for RAG"                        â”‚
â”‚  }                                                            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
      â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Firestore: NOW DUAL-MODE                                     â”‚
â”‚                                                               â”‚
â”‚  context_sources/src_abc123:                                  â”‚
â”‚  {                                                            â”‚
â”‚    extractedData: "Full text...",     â† Mode 1: ALWAYS works â”‚
â”‚    ragEnabled: true,                  â† Mode 2: NOW availableâ”‚
â”‚    ragMetadata: { totalChunks: 100 }                          â”‚
â”‚  }                                                            â”‚
â”‚                                                               â”‚
â”‚  document_chunks/ (100 documents):    â† Mode 2: RAG chunks   â”‚
â”‚  chunk_001: { text: "...", embedding: [...] }                â”‚
â”‚  chunk_002: { text: "...", embedding: [...] }                â”‚
â”‚  chunk_003: { text: "...", embedding: [...] }                â”‚
â”‚  ...                                                          â”‚
â”‚  chunk_100: { text: "...", embedding: [...] }                â”‚
â”‚                                                               â”‚
â”‚  âœ… Document now supports BOTH modes!                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜


â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      3a. Q&A - MODE 1 (Full-Text)                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

User query: "What were Q4 sales?"
RAG disabled OR no chunks available
      â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  /api/conversations/:id/messages                              â”‚
â”‚                                                               â”‚
â”‚  // Build context from full documents                         â”‚
â”‚  const additionalContext = contextSources                     â”‚
â”‚    .filter(s => s.enabled)                                    â”‚
â”‚    .map(source => `                                           â”‚
â”‚      === ${source.name} ===                                   â”‚
â”‚      ${source.extractedData}                                  â”‚
â”‚    `)                                                         â”‚
â”‚    .join('\n\n');                                             â”‚
â”‚                                                               â”‚
â”‚  // Send to Gemini                                            â”‚
â”‚  const aiResponse = await generateAIResponse(message, {       â”‚
â”‚    model: 'gemini-2.5-flash',                                 â”‚
â”‚    systemInstruction: systemPrompt,                           â”‚
â”‚    userContext: additionalContext,  â† Full document (50K)    â”‚
â”‚    conversationHistory: [...]                                 â”‚
â”‚  });                                                          â”‚
â”‚                                                               â”‚
â”‚  Tokens sent: 50,000                                          â”‚
â”‚  Response time: 4.2s                                          â”‚
â”‚  Cost: $0.0625 (Pro model)                                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
      â†“
    Answer delivered (complete context)


â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      3b. Q&A - MODE 2 (RAG Search)                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

User query: "What were Q4 sales?"
RAG enabled AND chunks available
      â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  /api/conversations/:id/messages                              â”‚
â”‚                                                               â”‚
â”‚  // Try RAG search first                                      â”‚
â”‚  import { searchRelevantChunks, buildRAGContext }             â”‚
â”‚         from '../../../lib/rag-search';                       â”‚
â”‚                                                               â”‚
â”‚  const ragResults = await searchRelevantChunks(               â”‚
â”‚    userId,                                                    â”‚
â”‚    message,  // "What were Q4 sales?"                         â”‚
â”‚    {                                                          â”‚
â”‚      topK: 5,                        â† Get top 5 chunks      â”‚
â”‚      minSimilarity: 0.5,             â† 50% similar or more   â”‚
â”‚      activeSourceIds: ['src_abc123'] â† Filter by doc         â”‚
â”‚    }                                                          â”‚
â”‚  );                                                           â”‚
â”‚                                                               â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”           â”‚
â”‚  â”‚ RAG Search Process:                            â”‚           â”‚
â”‚  â”‚                                                â”‚           â”‚
â”‚  â”‚ 1. Generate query embedding                    â”‚           â”‚
â”‚  â”‚    const queryEmbed =                          â”‚           â”‚
â”‚  â”‚      await generateEmbedding(                  â”‚           â”‚
â”‚  â”‚        "What were Q4 sales?"                   â”‚           â”‚
â”‚  â”‚      );                                        â”‚           â”‚
â”‚  â”‚    // [0.145, 0.432, ..., 0.267]              â”‚           â”‚
â”‚  â”‚                                                â”‚           â”‚
â”‚  â”‚ 2. Load all chunks for user                    â”‚           â”‚
â”‚  â”‚    const chunks = await firestore              â”‚           â”‚
â”‚  â”‚      .collection('document_chunks')            â”‚           â”‚
â”‚  â”‚      .where('userId', '==', userId)            â”‚           â”‚
â”‚  â”‚      .where('sourceId', 'in', activeSourceIds) â”‚           â”‚
â”‚  â”‚      .get();                                   â”‚           â”‚
â”‚  â”‚    // Loaded: 100 chunks                       â”‚           â”‚
â”‚  â”‚                                                â”‚           â”‚
â”‚  â”‚ 3. Calculate similarity for each chunk         â”‚           â”‚
â”‚  â”‚    const similarities = chunks.map(chunk => ({ â”‚           â”‚
â”‚  â”‚      chunk,                                    â”‚           â”‚
â”‚  â”‚      similarity: cosineSimilarity(             â”‚           â”‚
â”‚  â”‚        queryEmbed,                             â”‚           â”‚
â”‚  â”‚        chunk.embedding                         â”‚           â”‚
â”‚  â”‚      )                                         â”‚           â”‚
â”‚  â”‚    }));                                        â”‚           â”‚
â”‚  â”‚                                                â”‚           â”‚
â”‚  â”‚    Results:                                    â”‚           â”‚
â”‚  â”‚    - Chunk 23: 0.89 (89% similar) âœ“           â”‚           â”‚
â”‚  â”‚    - Chunk 45: 0.84 (84% similar) âœ“           â”‚           â”‚
â”‚  â”‚    - Chunk 67: 0.79 (79% similar) âœ“           â”‚           â”‚
â”‚  â”‚    - Chunk 12: 0.71 (71% similar) âœ“           â”‚           â”‚
â”‚  â”‚    - Chunk 89: 0.68 (68% similar) âœ“           â”‚           â”‚
â”‚  â”‚    - Chunk 34: 0.42 (42% similar) âœ— Skip     â”‚           â”‚
â”‚  â”‚    - ... (95 others < 50% - skip)             â”‚           â”‚
â”‚  â”‚                                                â”‚           â”‚
â”‚  â”‚ 4. Select top 5 above threshold                â”‚           â”‚
â”‚  â”‚    const topChunks = similarities              â”‚           â”‚
â”‚  â”‚      .filter(s => s.similarity >= 0.5)         â”‚           â”‚
â”‚  â”‚      .sort((a,b) => b.similarity - a.similarity)â”‚           â”‚
â”‚  â”‚      .slice(0, 5);                             â”‚           â”‚
â”‚  â”‚                                                â”‚           â”‚
â”‚  â”‚ 5. Build context from selected chunks          â”‚           â”‚
â”‚  â”‚    const context = buildRAGContext(topChunks); â”‚           â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜           â”‚
â”‚                                                               â”‚
â”‚  const additionalContext = `                                  â”‚
â”‚    === Document.pdf (RAG: 5 relevant chunks) ===              â”‚
â”‚                                                               â”‚
â”‚    [Chunk 23, Relevance: 89%]                                 â”‚
â”‚    Q4 sales reached $175K, representing...                    â”‚
â”‚                                                               â”‚
â”‚    [Chunk 45, Relevance: 84%]                                 â”‚
â”‚    The bar chart shows quarterly progression...               â”‚
â”‚                                                               â”‚
â”‚    [Chunk 67, Relevance: 79%]                                 â”‚
â”‚    Revenue breakdown by quarter indicates...                  â”‚
â”‚  `;                                                           â”‚
â”‚                                                               â”‚
â”‚  // Send to Gemini                                            â”‚
â”‚  const aiResponse = await generateAIResponse(message, {       â”‚
â”‚    model: 'gemini-2.5-flash',                                 â”‚
â”‚    systemInstruction: systemPrompt,                           â”‚
â”‚    userContext: additionalContext,  â† Relevant chunks (2.5K) â”‚
â”‚    conversationHistory: [...]                                 â”‚
â”‚  });                                                          â”‚
â”‚                                                               â”‚
â”‚  Tokens sent: 2,500 (95% reduction!)                          â”‚
â”‚  Response time: 1.8s (2.3x faster!)                           â”‚
â”‚  Cost: $0.003 (95% cheaper!)                                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
      â†“
    Answer delivered (focused, relevant context)
```

---

## ðŸ”„ Dual-Mode Intelligence

### The System Automatically Chooses:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Query arrives                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â”‚
               â–¼
        Check: RAG available?
               â”‚
       â”Œâ”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”
       â”‚                â”‚
      YES              NO
       â”‚                â”‚
       â–¼                â–¼
   Try RAG         Use Full-Text
       â”‚                â”‚
       â–¼                â”‚
   Success?             â”‚
       â”‚                â”‚
   â”Œâ”€â”€â”€â”´â”€â”€â”€â”            â”‚
  YES     NO            â”‚
   â”‚       â”‚            â”‚
   â”‚       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
   â”‚                    â”‚
   â–¼                    â–¼
Use RAG           Use Full-Text
(2.5K tokens)     (50K tokens)
   â”‚                    â”‚
   â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
            â”‚
            â–¼
      Gemini AI gets best available context
            â”‚
            â–¼
         Answer
```

**Intelligent fallback at every step** âœ…

---

## ðŸ“‹ Implementation Interfaces

### Interface 1: Enable RAG for Document

**NEW API Endpoint:**

```typescript
// src/pages/api/context-sources/[id]/enable-rag.ts

export const POST: APIRoute = async ({ params, request }) => {
  const { id } = params;  // sourceId
  const body = await request.json();
  const { userId, chunkSize = 500, overlap = 50 } = body;

  // 1. Load source
  const source = await firestore
    .collection('context_sources')
    .doc(id)
    .get();

  if (!source.exists || source.data().userId !== userId) {
    return new Response(
      JSON.stringify({ error: 'Source not found' }),
      { status: 404 }
    );
  }

  const extractedText = source.data().extractedData;

  // 2. Chunk text
  const { chunkTextSmart } = await import('../../lib/chunking.js');
  const chunks = chunkTextSmart(extractedText, chunkSize);

  // 3. Generate embeddings
  const { generateEmbeddingsBatch } = await import('../../lib/embeddings.js');
  const chunkTexts = chunks.map(c => c.text);
  const embeddings = await generateEmbeddingsBatch(chunkTexts);

  // 4. Store chunks
  const batch = firestore.batch();
  chunks.forEach((chunk, i) => {
    const chunkDoc = firestore.collection('document_chunks').doc();
    batch.set(chunkDoc, {
      sourceId: id,
      userId,
      chunkIndex: i,
      text: chunk.text,
      embedding: embeddings[i],
      metadata: {
        startChar: chunk.startChar,
        endChar: chunk.endChar,
        tokenCount: chunk.tokenCount
      },
      createdAt: new Date()
    });
  });
  await batch.commit();

  // 5. Update source
  await source.ref.update({
    ragEnabled: true,
    ragMetadata: {
      totalChunks: chunks.length,
      embeddingModel: 'text-embedding-004',
      embeddingDimensions: 768,
      chunkSize,
      indexedAt: new Date()
    }
  });

  return new Response(
    JSON.stringify({
      success: true,
      chunksCreated: chunks.length
    }),
    { status: 200 }
  );
};
```

---

### Interface 2: Query with RAG

**EXISTING (Already Modified):**

```typescript
// src/pages/api/conversations/[id]/messages.ts

export const POST: APIRoute = async ({ params, request }) => {
  const { userId, message, contextSources, ragEnabled } = await request.json();

  let additionalContext = '';
  let ragUsed = false;

  if (contextSources && contextSources.length > 0) {
    const activeSourceIds = contextSources.map(s => s.id);

    // Try RAG if enabled
    if (ragEnabled) {
      const { searchRelevantChunks, buildRAGContext } = 
        await import('../../../lib/rag-search.js');

      const ragResults = await searchRelevantChunks(userId, message, {
        topK: 5,
        minSimilarity: 0.5,
        activeSourceIds
      });

      if (ragResults.length > 0) {
        // RAG success - use chunks
        additionalContext = buildRAGContext(ragResults);
        ragUsed = true;
      } else {
        // No results - fall back to full-text
        additionalContext = contextSources
          .map(s => `=== ${s.name} ===\n${s.content}`)
          .join('\n');
      }
    } else {
      // RAG disabled - use full-text
      additionalContext = contextSources
        .map(s => `=== ${s.name} ===\n${s.content}`)
        .join('\n');
    }
  }

  // Send to Gemini
  const aiResponse = await generateAIResponse(message, {
    userContext: additionalContext,
    // ... other options
  });

  return new Response(JSON.stringify({
    message: aiResponse,
    ragStats: ragUsed ? { chunks: 5, tokens: 2500 } : null
  }));
};
```

---

## ðŸŽ¯ Complementary Benefits

### Documents WITHOUT RAG:

- âœ… Work immediately after upload
- âœ… Full context available
- âœ… No indexing wait time
- âœ… Good for small documents (<10 pages)

**Use case:** Quick uploads, small docs, exploratory analysis

---

### Documents WITH RAG:

- âœ… 95% token reduction
- âœ… 2-3x faster responses
- âœ… More focused answers
- âœ… Support larger libraries

**Use case:** Large docs, frequent queries, production use

---

### Mixed Mode (BEST):

**User has 10 documents:**
- 3 small PDFs (10 pages each) â†’ Full-text mode
- 7 large PDFs (100 pages each) â†’ RAG mode

**Query uses both:**
- Small docs: Send full text (no overhead)
- Large docs: Send relevant chunks (efficient)
- **Result: Optimal efficiency for each document type** âœ…

---

## ðŸš€ Implementation Plan

### Phase 1: Enable RAG Indexing (Next)

**Create new endpoint:**

```typescript
// src/pages/api/context-sources/[id]/enable-rag.ts
```

**Triggered by:**
- User clicks "Enable RAG" on document
- Admin clicks "Bulk Index All"
- Automatic after upload (future - if size >10 pages)

---

### Phase 2: UI Integration (After)

**Add button to context source settings:**
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Document Settings                    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                      â”‚
â”‚ âœ… Extracted: 48,234 characters      â”‚
â”‚                                      â”‚
â”‚ RAG Status: Not indexed              â”‚
â”‚                                      â”‚
â”‚ [ðŸ” Index for RAG Search]            â”‚ â† NEW button
â”‚                                      â”‚
â”‚ Benefits:                             â”‚
â”‚ â€¢ 95% token reduction                â”‚
â”‚ â€¢ 2x faster responses                â”‚
â”‚ â€¢ More focused answers               â”‚
â”‚                                      â”‚
â”‚ Cost: ~$0.005 (one-time)             â”‚
â”‚ Time: ~15 seconds                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

### Phase 3: Admin Bulk Operations (After)

**Admin panel button:**
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ RAG Configuration - Maintenance      â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                      â”‚
â”‚ Sources without RAG: 47              â”‚
â”‚                                      â”‚
â”‚ [ðŸ”„ Index All Documents]             â”‚ â† Bulk operation
â”‚                                      â”‚
â”‚ This will:                            â”‚
â”‚ â€¢ Process 47 documents                â”‚
â”‚ â€¢ Create ~4,700 chunks                â”‚
â”‚ â€¢ Cost: ~$0.25 total                 â”‚
â”‚ â€¢ Time: ~15 minutes                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ðŸ’¡ Why This Architecture is Perfect

### 1. **Non-Destructive** âœ…
- Original extractedData preserved
- RAG chunks are additions (not replacements)
- Can disable RAG anytime
- Original full-text always works

### 2. **Flexible** âœ…
- Per-document RAG enable/disable
- Per-user RAG preferences
- System-wide defaults
- Graceful fallback

### 3. **Optimal** âœ…
- Small docs: No RAG overhead
- Large docs: Maximum efficiency
- Mixed queries: Best of both
- Intelligent mode selection

### 4. **Cost-Effective** âœ…
- One-time indexing cost (~$0.005/doc)
- Massive query savings (99%)
- User controls trade-offs
- ROI < 1 day

---

## ðŸŽ¯ Summary

**Your understanding:**
> "RAG should be used after the initial extraction, leverage multimodal extraction to get complete text, then embed that"

**Status:** âœ… **EXACTLY RIGHT!**

**Architecture:**
- Multimodal extraction FIRST (capture everything)
- RAG indexing SECOND (optimize search)
- Dual-mode querying THIRD (intelligent selection)
- **Complementary, not replacement** âœ…

**Next steps:**
1. Create `/api/context-sources/[id]/enable-rag` endpoint
2. Add "Index for RAG" button to UI
3. Test with one document
4. Enable for more when ready

**Want me to implement the enable-rag endpoint now?** ðŸš€
