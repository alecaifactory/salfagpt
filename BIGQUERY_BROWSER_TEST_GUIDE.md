# ğŸ§ª BigQuery GREEN vs BLUE - Browser Testing Guide

**Test Agent:** GESTION BODEGAS GPT (S001)  
**Agent ID:** AjtQZEIMQvFnPRJRjl4y âœ… (Found)  
**Status:** Ready to test in browser

---

## ğŸš€ **How to Run the Test**

### **Step 1: Ensure Dev Server Running**

```bash
# Check if running
curl -s -o /dev/null -w "%{http_code}" http://localhost:3000/chat

# If not 302, start it:
npm run dev
```

**Server should be on:** http://localhost:3000

---

### **Step 2: Open Browser Test**

1. **Open:** http://localhost:3000/chat
2. **Login** with your account
3. **Find agent:** "GESTION BODEGAS GPT (S001)"
4. **Click** to open that agent

---

### **Step 3: Test Query with GREEN (Automatic)**

**Since you're on localhost, router will automatically use GREEN!**

**Send this message:**
```
Â¿CuÃ¡l es el procedimiento para inventario de existencias MB52?
```

**Watch the browser console (F12 â†’ Console):**

**Expected logs (GREEN):**
```
ğŸ”€ BigQuery Routing Decision:
  Origin: http://localhost:3000
  Selected: GREEN (optimized) âœ…

[OPTIMIZED] BigQuery Vector Search starting...
  [1/4] Generating query embedding...
  âœ“ Embedding ready (800-1000ms)
  [2/4] Loading sources assigned to agent...
  âœ“ Found X sources (100-200ms)
  [3/4] Executing BigQuery vector search...
  âœ“ Search complete (400-500ms)
  âœ“ Found X chunks
  [4/4] Loading source names...
  âœ“ Names loaded (50ms)

âœ… [OPTIMIZED] Search complete (1,400-1,800ms) â† Should be <2s!
  Results: X chunks
  Avg similarity: XX%
```

---

### **Step 4: Verify Performance**

**Measure total response time:**
```
From: Click Send
To: First text appears
Target: <8 seconds total
  - Thinking: <1s to appear
  - Searching: <2s  (GREEN target)
  - Streaming: 2-3s
```

**Check similarity scores in references:**
```
Should show: 70-95% (real scores)
Not: 50% (dummy fallback scores)
```

---

### **Step 5: Compare with BLUE (Manual Switch)**

**To test BLUE for comparison:**

```bash
# Terminal (where server is running):
# Stop server: Ctrl+C

# Set flag to force BLUE
export USE_OPTIMIZED_BIGQUERY=false

# Restart
npm run dev
```

**Then repeat same test:**
- Same agent
- Same query
- Compare performance

**Expected logs (BLUE):**
```
ğŸ”€ BigQuery Routing Decision:
  Origin: http://localhost:3000
  Override: Force BLUE (env var) âœ…

BigQuery Agent Search starting...
  (BLUE implementation logs)
  ...
  
Might see:
  âš ï¸ Falling back to Firestore (if BLUE has issues)
  (Then 120s delay)
```

---

## ğŸ“Š **What to Measure**

### **Performance Metrics:**

| Metric | GREEN Target | BLUE Current | Pass/Fail |
|--------|-------------|--------------|-----------|
| **Thinking appears** | <1s | Variable | ? |
| **RAG search time** | <2s | 400ms - 120s | ? |
| **Total response** | <8s | 10s - 130s | ? |
| **Results found** | >0 | Variable | ? |
| **Avg similarity** | 70-95% | Variable | ? |

### **User Experience:**

| Aspect | GREEN Expected | BLUE Current | Better? |
|--------|---------------|--------------|---------|
| **Wait time** | <8s | 10-130s | ? |
| **Visual feedback** | Immediate | Delayed | ? |
| **Result quality** | High (70-95%) | Variable | ? |
| **Feeling** | "Professional" | "Slow/Broken" | ? |

---

## ğŸ¯ **Success Criteria**

### **GREEN Passes If:**
- [ ] Router logs show "Selected: GREEN"
- [ ] Search completes in <2s
- [ ] Returns >0 results
- [ ] Similarity scores 70-95%
- [ ] Total response <8s
- [ ] No Firestore fallback
- [ ] You say "This is fast!"

### **GREEN Needs Work If:**
- [ ] Search takes 2-5s (acceptable but not optimal)
- [ ] Returns 0 results (agent assignment issue)
- [ ] Similarity scores 50-70% (acceptable quality)
- [ ] Total response 8-15s (could be better)

### **GREEN Fails If:**
- [ ] Errors in console
- [ ] Falls back to Firestore (120s)
- [ ] Returns 0 results consistently
- [ ] Performance >5s

---

## ğŸ” **Troubleshooting**

### **If "0 sources found":**
```
Possible causes:
1. Agent has no sources assigned (check assignedToAgents field)
2. Sources exist but for different userId  
3. Query logic issue

Solution:
- Try different agent
- Check Firestore: context_sources collection
- Verify assignedToAgents array includes this agentId
```

### **If "Falling back to Firestore":**
```
Possible causes:
1. GREEN table query failed
2. GREEN returned 0 (genuine no matches)
3. userId format mismatch

Solution:
- Check GREEN table has data (we verified it does âœ…)
- Check userId in query matches table data
- Review console error logs
```

### **If Performance >2s:**
```
Possible causes:
1. Embedding generation slow (800-1000ms - normal)
2. BigQuery cold start (first query only)
3. No vector index (each query recalculates)

Solution:
- Accept embedding time (can't optimize much)
- Wait for subsequent queries (will be faster)
- Create vector index (optional, helps cold-start)
```

---

## ğŸ“Š **Expected Benchmark Results**

### **GREEN (Optimized):**
```
Performance:
â”œâ”€ Embedding: 800-1,000ms
â”œâ”€ Source lookup: 100-200ms  
â”œâ”€ Vector search: 400-500ms
â”œâ”€ Name loading: 50-100ms
â””â”€ TOTAL: 1,400-1,800ms âœ… (<2s target)

Quality:
â”œâ”€ Results: 5-8 chunks
â”œâ”€ Similarity: 70-95%
â””â”€ Relevant: High

UX:
â”œâ”€ Thinking: Appears immediately
â”œâ”€ Response: <8s total
â””â”€ Feeling: "Professional and fast"
```

### **BLUE (Current - if works):**
```
Performance:
â”œâ”€ Embedding: 800-1,000ms
â”œâ”€ Source lookup: 100-200ms
â”œâ”€ Vector search: 400-500ms (if no fallback)
â”œâ”€ OR Firestore fallback: 120,000ms (if returns 0)
â””â”€ TOTAL: 1,400ms or 120s (inconsistent)

Quality:
â”œâ”€ Results: 5-8 chunks (when works)
â”œâ”€ Similarity: Variable or 50% (fallback)
â””â”€ Relevant: Variable

UX:
â”œâ”€ Thinking: May appear late
â”œâ”€ Response: 8s or 130s (unpredictable)
â””â”€ Feeling: "Fast or broken" (inconsistent)
```

---

## ğŸ¯ **What We're Looking For**

### **GREEN Success Indicators:**
```
Console logs:
âœ… "Routing to: OPTIMIZED BigQuery"
âœ… "[OPTIMIZED] Search complete (450ms)"
âœ… "Found 8 chunks"
âœ… "Avg similarity: 82%"
âœ… "TOTAL: 1,550ms"

UI experience:
âœ… Response in <8s
âœ… Thinking appears <1s
âœ… References with real scores
âœ… No long pauses
```

### **BLUE Issues (What We're Fixing):**
```
Console logs:
âš ï¸ "BigQuery search found 0 chunks"
âš ï¸ "Falling back to Firestore"
âŒ (118 seconds of processing)
âš ï¸ "Created emergency references"

UI experience:
âŒ 10-20s silence
âŒ Response in 120s
âŒ References with 50% dummy scores
âŒ User thinks it crashed
```

---

## ğŸš€ **Quick Test Commands**

### **Test GREEN (localhost automatic):**
```bash
# Just open browser - no config needed
open http://localhost:3000/chat

# Router uses GREEN automatically because:
# origin = "http://localhost:3000" â†’ GREEN
```

### **Force BLUE (for comparison):**
```bash
# Stop server
# Set flag
export USE_OPTIMIZED_BIGQUERY=false

# Restart
npm run dev

# Now localhost uses BLUE
# (Env var overrides domain routing)
```

### **Back to AUTO (domain-based):**
```bash
# Stop server
# Remove flag
unset USE_OPTIMIZED_BIGQUERY

# Restart
npm run dev

# localhost â†’ GREEN (automatic)
# production â†’ BLUE (automatic)
```

---

## ğŸ“‹ **Testing Checklist**

```
Preparation:
â”œâ”€ [ ] Dev server running (http://localhost:3000)
â”œâ”€ [ ] Browser open
â”œâ”€ [ ] Logged in
â”œâ”€ [ ] Console open (F12)
â””â”€ [ ] Agent selected: GESTION BODEGAS GPT (S001)

Test GREEN (default on localhost):
â”œâ”€ [ ] Send query: "Â¿Procedimiento inventario MB52?"
â”œâ”€ [ ] Console shows: "Selected: GREEN"
â”œâ”€ [ ] Search completes: <2s
â”œâ”€ [ ] Results found: >0
â”œâ”€ [ ] Similarity: >70%
â”œâ”€ [ ] Total response: <8s
â””â”€ [ ] No errors

Test BLUE (for comparison):
â”œâ”€ [ ] export USE_OPTIMIZED_BIGQUERY=false
â”œâ”€ [ ] Restart server
â”œâ”€ [ ] Same query
â”œâ”€ [ ] Console shows: "Using BLUE"
â”œâ”€ [ ] Compare performance
â””â”€ [ ] Document differences

Comparison:
â”œâ”€ [ ] GREEN faster than BLUE?
â”œâ”€ [ ] GREEN more results?
â”œâ”€ [ ] GREEN better similarity?
â”œâ”€ [ ] GREEN better UX?
â””â”€ [ ] GREEN ready for production?
```

---

## ğŸ’¡ **Pro Tips**

1. **Clear console between tests** - Easier to see routing decision
2. **Use same query** - Fair comparison
3. **Test 2-3 queries** - Verify consistency
4. **Note first vs subsequent** - Cold start vs warm
5. **Check similarity scores** - 70-95% = good, 50% = fallback

---

## ğŸŠ **What Success Looks Like**

### **GREEN Test Passing:**
```
You: Ask question
  â†“ (Immediate)
Console: "Routing to: GREEN"
  â†“ (<1s)
Console: "Search complete (450ms)"
  â†“ (<2s)
Console: "Found 8 chunks, 82% similarity"
  â†“ (2-3s)
UI: Response starts streaming
  â†“ (<8s total)
You: "Wow, this is fast!" âœ…
```

**Then you know:** GREEN works, ready for production when you approve.

---

##Ready for Browser Test**

**Everything is set up:**
- âœ… GREEN table populated (8,403 chunks)
- âœ… Domain routing ready (localhost â†’ GREEN)
- âœ… Server running (http://localhost:3000)
- âœ… Agent identified (GESTION BODEGAS S001)
- âœ… Test query prepared

**Just open the browser and test!**

**Or tell me:**
- "Test it for me" - I'll guide you through
- "Skip testing, looks good" - I'll document ready for production
- "Need more info" - I'll explain anything

**Your production is 100% safe. GREEN is ready. Just needs your validation.** ğŸ¯âœ¨

