# üß¨ RAG & Embeddings - Gu√≠a Completa

## üéØ ¬øQu√© es RAG?

**RAG (Retrieval-Augmented Generation)** es el proceso de:
1. **Chunk:** Dividir documentos en pedazos sem√°nticos
2. **Embed:** Convertir cada chunk en vector (embedding)
3. **Index:** Almacenar vectores para b√∫squeda r√°pida
4. **Search:** Encontrar chunks relevantes por similitud sem√°ntica
5. **Generate:** Usar chunks como contexto para el AI

---

## üî¨ Proceso Completo en el CLI

### Pipeline de 5 Pasos

```
üìÑ Documento ‚Üí üì§ Upload GCS ‚Üí ü§ñ Extracci√≥n ‚Üí üìê Chunking ‚Üí üß¨ Embeddings ‚Üí üíæ Index
```

**Detalles:**

#### Paso 1: Upload a GCS
- Archivo original guardado
- Path: `gs://bucket/{userId}/{agentId}/file.pdf`

#### Paso 2: Extracci√≥n con Gemini
- Texto completo extra√≠do
- Tablas convertidas a Markdown
- Im√°genes descritas

#### Paso 3: Guardado en Firestore
- Metadata + texto completo
- Collection: `context_sources`

#### Paso 4: Chunking Inteligente ‚≠ê NUEVO
- Texto dividido en chunks sem√°nticos
- Tama√±o: ~512 tokens por chunk
- Estrategia: Por p√°rrafo primero, luego por oraci√≥n si es necesario
- Resultado: Array de chunks con texto + posici√≥n

#### Paso 5: Generaci√≥n de Embeddings ‚≠ê NUEVO
- Cada chunk ‚Üí embedding de 768 dimensiones
- Modelo: `text-embedding-004`
- Almacenado en collection `document_embeddings`
- **Incluye user attribution:** alec@getaifactory.com
- **Incluye source tracking:** 'cli'

---

## üìä Estructura de Datos

### Collection: `document_embeddings`

```typescript
{
  id: "embedding-abc123",
  
  // Referencias
  documentId: "source-xyz789",        // Link a context_sources
  fileName: "manual-producto.pdf",
  userId: "114671162830729001607",
  agentId: "cli-upload",
  
  // Chunk info
  chunkIndex: 0,                      // Orden del chunk (0, 1, 2, ...)
  chunkText: "# Manual de Producto\n\nBienvenido al manual...",
  tokenCount: 487,                    // Tokens en este chunk
  
  // Vector embedding
  embedding: [0.123, -0.456, 0.789, ...],  // 768 n√∫meros (dimensiones)
  embeddingModel: "text-embedding-004",
  
  // ‚≠ê TRACEABILIDAD
  uploadedVia: "cli",                 // Fuente: CLI
  cliVersion: "0.3.0",                // Versi√≥n del CLI
  userEmail: "alec@getaifactory.com", // Usuario que solicit√≥
  source: "cli",                      // Source tracking
  
  // Timestamps
  createdAt: Timestamp,
  indexedAt: Timestamp,
}
```

---

## üîç D√≥nde Quedan los Vectores

### Firestore Collection: `document_embeddings`

**URL:**
```
https://console.firebase.google.com/project/gen-lang-client-0986191192/firestore/data/~2Fdocument_embeddings
```

**Estructura por documento:**
```
document_embeddings/
‚îú‚îÄ‚îÄ embedding-1: { chunkIndex: 0, text: "...", embedding: [...768 dims], userEmail: "alec@..." }
‚îú‚îÄ‚îÄ embedding-2: { chunkIndex: 1, text: "...", embedding: [...768 dims], userEmail: "alec@..." }
‚îú‚îÄ‚îÄ embedding-3: { chunkIndex: 2, text: "...", embedding: [...768 dims], userEmail: "alec@..." }
‚îî‚îÄ‚îÄ ...
```

**Cada documento de 10 p√°ginas genera ~15-20 chunks/embeddings**

---

## üìê Algoritmo de Chunking

### Estrategia

1. **Split por p√°rrafos** (`\n\n`)
2. Si p√°rrafo > 512 tokens ‚Üí **split por oraciones**
3. Acumular hasta llegar a 512 tokens
4. Crear nuevo chunk
5. Mantener contexto (no cortar palabras/oraciones)

### Ejemplo

**Texto original:**
```
# Manual de Producto

Bienvenido al manual completo de nuestro producto estrella...
(5,000 palabras)
```

**Resultado:**
```
Chunk 0 (487 tokens):
"# Manual de Producto\n\nBienvenido al manual..."

Chunk 1 (512 tokens):
"...continuaci√≥n del manual. Caracter√≠sticas principales..."

Chunk 2 (498 tokens):
"...instrucciones de instalaci√≥n..."

...

Chunk N (412 tokens):
"...conclusi√≥n y contacto."
```

**Total:** ~10-15 chunks por documento de 10 p√°ginas

---

## üß¨ Generaci√≥n de Embeddings

### Modelo: `text-embedding-004`

**Caracter√≠sticas:**
- **Dimensiones:** 768
- **Input m√°ximo:** 2,048 tokens
- **Output:** Array de 768 n√∫meros flotantes
- **Precio:** $0.00002 per 1K tokens
- **Latencia:** ~100-200ms por chunk

### Proceso

```typescript
Para cada chunk:
  1. Enviar texto a Gemini Embedding API
  2. Recibir vector de 768 dimensiones
  3. Guardar en Firestore con metadata completa
  4. Incluir:
     - userEmail: "alec@getaifactory.com" ‚≠ê
     - uploadedVia: "cli" ‚≠ê
     - source: "cli" ‚≠ê
```

### Ejemplo de Embedding

**Input (chunk de texto):**
```
# Manual de Producto

Bienvenido al manual completo de nuestro producto...
```

**Output (vector de 768 dimensiones):**
```
[
  0.123456,
  -0.234567,
  0.345678,
  -0.456789,
  ...
  (768 n√∫meros en total)
]
```

Este vector captura el **significado sem√°ntico** del texto.

---

## üîç B√∫squeda Sem√°ntica (Pr√≥ximamente)

### C√≥mo Funciona

1. **Query del usuario:** "pol√≠tica de devoluciones"
2. **Convertir query a embedding:** [0.111, -0.222, ...]
3. **Buscar vectores similares:** Calcular distancia coseno
4. **Ordenar por relevancia:** Top 5 chunks m√°s similares
5. **Usar como contexto:** Enviar chunks al AI

### Query Example (Firestore)

```typescript
// Simplified version (real implementation uses vector similarity)
const embeddings = await firestore
  .collection('document_embeddings')
  .where('userId', '==', '114671162830729001607')
  .where('agentId', '==', 'agent-M001')
  .where('userEmail', '==', 'alec@getaifactory.com')  // ‚≠ê Filter by user
  .get();

// Calculate cosine similarity
const queryEmbedding = await generateEmbedding(userQuery);
const results = embeddings.docs
  .map(doc => ({
    chunk: doc.data().chunkText,
    similarity: cosineSimilarity(queryEmbedding, doc.data().embedding),
    uploadedVia: doc.data().uploadedVia,  // ‚≠ê Know it came from CLI
    userEmail: doc.data().userEmail,      // ‚≠ê Know who uploaded it
  }))
  .sort((a, b) => b.similarity - a.similarity)
  .slice(0, 5);  // Top 5

// Use results as context for AI
```

---

## üí∞ Costos

### Por Documento (Promedio)

**Documento de 10 p√°ginas (~5,000 palabras):**

| Paso | Operaci√≥n | Tokens | Costo |
|------|-----------|--------|-------|
| 1. Upload GCS | - | - | $0.00001 |
| 2. Extracci√≥n | Gemini Flash | ~4,000 out | $0.001200 |
| 3. Chunking | - | - | $0 |
| 4. Embeddings | 15 chunks √ó 500 tokens | 7,500 | $0.000150 |
| **TOTAL** | | | **$0.001350** |

**11 documentos:** ~$0.015 total

---

## üìç Verificaci√≥n de Vectores

### Check document_embeddings Collection

```bash
# Ver cu√°ntos embeddings tienes
npx tsx -e "
import { firestore } from './src/lib/firestore.js';

const embeds = await firestore
  .collection('document_embeddings')
  .where('userEmail', '==', 'alec@getaifactory.com')
  .count()
  .get();

console.log('üìä Total embeddings:', embeds.data().count);
process.exit(0);
"
```

### Ver embeddings de un documento

```bash
npx tsx -e "
import { firestore } from './src/lib/firestore.js';

const documentId = 'YOUR_DOC_ID';  // From CLI output

const embeds = await firestore
  .collection('document_embeddings')
  .where('documentId', '==', documentId)
  .orderBy('chunkIndex', 'asc')
  .get();

console.log(\`üì¶ Chunks del documento \${documentId}:\n\`);

embeds.forEach(doc => {
  const d = doc.data();
  console.log(\`Chunk \${d.chunkIndex}:\`);
  console.log(\`  Texto: \${d.chunkText.substring(0, 100)}...\`);
  console.log(\`  Tokens: \${d.tokenCount}\`);
  console.log(\`  Embedding: [\${d.embedding.slice(0, 5).join(', ')}, ...] (768 dims)\`);
  console.log(\`  Usuario: \${d.userEmail}\`);
  console.log(\`  Fuente: \${d.source}\`);
  console.log('');
});

process.exit(0);
"
```

---

## üéØ User Attribution en Vectores

### Todos los embeddings incluyen:

```typescript
{
  // ‚≠ê TRACEABILIDAD
  userEmail: "alec@getaifactory.com",    // Quien subi√≥ el documento
  uploadedVia: "cli",                     // C√≥mo se subi√≥ (cli vs webapp)
  source: "cli",                          // Source tracking
  cliVersion: "0.3.0",                    // Versi√≥n del CLI usado
  
  // Tambi√©n en el documento padre (context_sources)
  metadata: {
    userEmail: "alec@getaifactory.com",
    uploadedVia: "cli",
    ragProcessedBy: "alec@getaifactory.com",  // Quien proces√≥ RAG
  }
}
```

### Por qu√© esto es importante:

1. **Auditor√≠a:** Saber qui√©n cre√≥ qu√© vectores
2. **Costos:** Atribuir costos por usuario
3. **Debugging:** Identificar problemas por fuente
4. **Analytics:** CLI vs webapp usage patterns
5. **Compliance:** Trazabilidad completa para regulaci√≥n

---

## üìä Estad√≠sticas del Proceso

### Output del CLI (v0.3)

```
üß¨ RAG & Vector Indexing:
   Total Chunks: 45
   Total Embeddings: 45 (768-dim cada uno)
   Modelo Embeddings: text-embedding-004
   Tiempo Total RAG: 8.3s
   Promedio por Archivo: 8.3s

üí∞ Costos:
   Extracci√≥n (Gemini): $0.001234
   Embeddings (RAG): $0.000180
   Total: $0.001414
   Promedio por Archivo: $0.001414

‚òÅÔ∏è  Recursos Creados en GCP:
   Storage: 1 archivo(s) en gs://...
   Firestore context_sources: 1 documento(s)
   Firestore document_embeddings: 45 chunks vectorizados ‚≠ê
   üîç B√∫squeda sem√°ntica: Habilitada para 1 documentos
```

---

## üîÆ Pr√≥ximos Pasos (v0.4+)

### B√∫squeda Sem√°ntica

**Comando (futuro):**
```bash
npx tsx cli/index.ts search "pol√≠tica de devoluciones" --agent M001
```

**Output:**
```
üîç Buscando: "pol√≠tica de devoluciones"
üéØ Top 5 resultados:

1. manual-producto.pdf (Chunk 3) - Similitud: 92%
   "...las pol√≠ticas de devoluci√≥n permiten..."
   
2. faq-cliente.pdf (Chunk 7) - Similitud: 87%
   "...para devolver un producto contacte..."

...
```

### BigQuery Migration (v0.5+)

Para mejor performance con >10,000 chunks:

```sql
CREATE TABLE `gen-lang-client-0986191192.flow_analytics.document_embeddings` (
  chunk_id STRING,
  document_id STRING,
  user_id STRING,
  user_email STRING,       -- ‚≠ê User attribution
  agent_id STRING,
  chunk_index INT64,
  chunk_text STRING,
  embedding ARRAY<FLOAT64>,  -- 768 dimensions
  token_count INT64,
  
  -- Traceability
  uploaded_via STRING,     -- 'cli' or 'webapp'
  cli_version STRING,
  source STRING,           -- 'cli'
  
  created_at TIMESTAMP,
  indexed_at TIMESTAMP
)
PARTITION BY DATE(created_at)
CLUSTER BY user_email, agent_id;
```

---

**Last Updated:** 2025-10-19  
**CLI Version:** 0.3.0  
**Status:** ‚úÖ RAG Implemented

