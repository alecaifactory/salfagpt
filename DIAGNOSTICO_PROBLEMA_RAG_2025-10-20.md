# ğŸ” DiagnÃ³stico del Problema RAG - 2025-10-20

## ğŸ“‹ Tabla Comparativa: Esperado vs Real

### Pregunta del Usuario:
```
"que sabemos de esto? 'Lo expuesto hasta ahora lleva a una primera conclusiÃ³n cual es 
que el caso en consulta debe resolverse teniendo presente la Ley NÂº19.537'"
```

### Estado del Sistema:
- **Chunks disponibles:** 5 chunks (indexados)
- **RAG habilitado:** âœ… SÃ­ (toggle verde)
- **Threshold:** 0 (muestra todos)
- **Embeddings:** Vertex AI (intentando semÃ¡nticos)

---

## ğŸ“Š Tabla: Esperado vs Real

| Aspecto | ESPERADO | REAL (Screenshot) | Status |
|---------|----------|-------------------|--------|
| **BÃºsqueda RAG** | âœ… Busca en 5 chunks | âš ï¸ Fallback a Full | âŒ FALLA |
| **Chunks usados** | Chunk #2 (contiene texto exacto) | Documento completo | âŒ FALLA |
| **Similitud** | ~85-95% (contiene frase exacta) | 100.0% | âŒ INCORRECTO |
| **Modo mostrado** | ğŸ” RAG | âš ï¸ Full | âŒ FALLA |
| **Referencias** | [1] Fragmento 2 - 95% similar | [1] 100% - Chunk #0 - Doc. Completo | âŒ INCORRECTO |
| **Tokens enviados** | ~465 tokens (solo Chunk #2) | 2,023 tokens (todo) | âŒ INEFICIENTE |
| **Badge** | ğŸ” RAG | ğŸ“ Full-Text Mode | âŒ INCORRECTO |

---

## ğŸš¨ Problema ROOT CAUSE

### El texto buscado ESTÃ LITERALMENTE en Chunk #2:

**Chunk #2 (465 tokens):**
```
5. Lo expuesto hasta ahora lleva a una primera conclusiÃ³n cual es que el caso en 
consulta debe resolverse teniendo presente la Ley NÂº19.537, desde el momento que 
la ley NÂ°6.071 hoy en dÃ­a se encuentra derogada...
```

**Pregunta del usuario:**
```
"Lo expuesto hasta ahora lleva a una primera conclusiÃ³n cual es que el caso en 
consulta debe resolverse teniendo presente la Ley NÂº19.537"
```

**Similitud esperada:** ~95% (es casi texto idÃ©ntico!)

**Similitud real:** 0% â†’ Fallback a Full-Text

---

## ğŸ” Por QuÃ© EstÃ¡ Pasando

### Causa 1: Vertex AI No Se EstÃ¡ Ejecutando

**Evidence del log:**
```
âš ï¸ Fallback: RAG no encontrÃ³ chunks relevantes, usÃ³ documentos completos
```

Esto significa que:
1. Sistema intentÃ³ RAG
2. No encontrÃ³ chunks (similarity = 0)
3. CayÃ³ en fallback (usar documento completo)

**Diagnosis:** Vertex AI embedding generation FAILED o NO se estÃ¡ usando

---

### Causa 2: Embeddings Siguen Siendo DeterminÃ­sticos

**Si Vertex AI fallÃ³:**
```
âŒ Vertex AI embedding generation failed: [error]
âš ï¸ Falling back to deterministic embedding
```

**Entonces:**
- Query embedding = hash determinÃ­stico
- Chunk embeddings = hash determinÃ­stico (de indexaciÃ³n anterior)
- Similarity = ~0% (diferentes textos = diferentes hashes)

---

### Causa 3: Chunks Tienen Embeddings Viejos (DeterminÃ­sticos)

**CRITICAL:**
Los chunks fueron indexados ANTES de implementar Vertex AI.
- Chunks en Firestore tienen embeddings determinÃ­sticos viejos
- Query usa embedding Vertex AI nuevo
- Comparar vectors de diferentes tipos â†’ similarity incorrecta

**SoluciÃ³n:** RE-INDEXAR documentos con Vertex AI

---

## âœ… SoluciÃ³n en 3 Pasos

### Paso 1: Verificar Vertex AI Funciona

**Test inmediato:**
```bash
npx tsx -e "
import { generateEmbedding } from './src/lib/embeddings.js';

(async () => {
  console.log('ğŸ§ª Testing Vertex AI embeddings...');
  
  try {
    const text = 'Lo expuesto hasta ahora lleva a una primera conclusiÃ³n';
    const embedding = await generateEmbedding(text);
    
    console.log('âœ… SUCCESS!');
    console.log('Embedding length:', embedding.length);
    console.log('First 5 values:', embedding.slice(0, 5));
    console.log('Type check:', embedding.every(v => typeof v === 'number'));
    
  } catch (error) {
    console.error('âŒ FAILED:', error.message);
  }
})();
"
```

**Expected:**
```
âœ… [Vertex AI] Generated semantic embedding: 768 dimensions
âœ… SUCCESS!
Embedding length: 768
First 5 values: [0.023, -0.045, 0.189, 0.234, -0.167]
Type check: true
```

**If fails:**
```
âŒ Vertex AI embedding generation failed: [error]
âš ï¸ Falling back to deterministic embedding
```

---

### Paso 2: Re-Indexar Cir32.pdf con Vertex AI

**Command:**
```bash
npx tsx scripts/reindex-document.ts --sourceId 8tjgUceVZW0A46QYYRfW
```

**Este script debe:**
1. Cargar los 5 chunks existentes de Firestore
2. Generar NUEVOS embeddings con Vertex AI para cada chunk
3. Actualizar chunks en Firestore con embeddings semÃ¡nticos
4. Marcar documento como re-indexado

**Expected logs:**
```
ğŸ”„ Re-indexing document: Cir32.pdf (5 chunks)
ğŸ§® [Vertex AI] Generating semantic embedding (Chunk #0)...
âœ… [Vertex AI] Generated semantic embedding: 768 dimensions
ğŸ§® [Vertex AI] Generating semantic embedding (Chunk #1)...
âœ… [Vertex AI] Generated semantic embedding: 768 dimensions
...
âœ… Re-indexed 5 chunks with Vertex AI embeddings
```

---

### Paso 3: Retry Query

**DespuÃ©s de re-indexar:**
1. Refresh pÃ¡gina
2. Hacer misma pregunta
3. Verificar logs

**Expected:**
```
ğŸ” RAG Search starting...
  âœ“ Found 5 similar chunks
  
Top chunks:
  1. Cir32.pdf (chunk 1) - 94.8% similar  â† CHUNK #2 en UI!
  2. Cir32.pdf (chunk 3) - 78.2% similar
  3. Cir32.pdf (chunk 0) - 65.1% similar
  
âœ… RAG: Using 3 relevant chunks (950 tokens)
```

**UI mostrarÃ¡:**
```
ğŸ“š Referencias utilizadas (3)

[1] Cir32.pdf - 94.8% similar
    Fragmento 1 - ğŸ” RAG
    465 tokens
    
[2] Cir32.pdf - 78.2% similar
    Fragmento 3 - ğŸ” RAG
    
[3] Cir32.pdf - 65.1% similar
    Fragmento 0 - ğŸ” RAG
```

---

## ğŸ¯ Root Cause Summary

### El Problema NO es el cÃ³digo:
- âœ… System prompt correcto (instrucciones RAG)
- âœ… Fragment mapping enviado
- âœ… Referencias construidas correctamente
- âœ… UI preparada para mostrar chunks

### El Problema ES los embeddings:
- âŒ Chunks tienen embeddings determinÃ­sticos viejos
- âŒ Query (posiblemente) usa embedding Vertex AI nuevo
- âŒ Comparar diferentes tipos de embeddings â†’ similarity = 0
- âŒ RAG no encuentra matches â†’ fallback a full-text

---

## ğŸ”§ Crear Script de Re-IndexaciÃ³n

**Archivo nuevo:** `scripts/reindex-document.ts`

```typescript
import { firestore } from '../src/lib/firestore';
import { generateEmbedding } from '../src/lib/embeddings';

async function reindexDocument(sourceId: string) {
  console.log('ğŸ”„ Re-indexing document with Vertex AI embeddings...');
  
  // 1. Load all chunks for this source
  const chunksSnapshot = await firestore
    .collection('document_chunks')
    .where('sourceId', '==', sourceId)
    .orderBy('chunkIndex', 'asc')
    .get();
  
  console.log(`ğŸ“Š Found ${chunksSnapshot.size} chunks to re-index`);
  
  // 2. Re-generate embeddings for each chunk
  let successCount = 0;
  let failCount = 0;
  
  for (const doc of chunksSnapshot.docs) {
    const chunkData = doc.data();
    console.log(`\nğŸ§® Processing Chunk #${chunkData.chunkIndex}...`);
    console.log(`  Text: ${chunkData.text.substring(0, 80)}...`);
    
    try {
      // Generate NEW semantic embedding
      const newEmbedding = await generateEmbedding(chunkData.text);
      
      // Update chunk in Firestore
      await doc.ref.update({
        embedding: newEmbedding,
        reindexedAt: new Date(),
        embeddingType: 'vertex-ai-semantic', // Mark as semantic
      });
      
      successCount++;
      console.log(`  âœ… Updated with ${newEmbedding.length}-dim semantic embedding`);
      
    } catch (error) {
      failCount++;
      console.error(`  âŒ Failed:`, error.message);
    }
  }
  
  // 3. Update source metadata
  await firestore.collection('context_sources').doc(sourceId).update({
    'ragMetadata.embeddingType': 'vertex-ai-semantic',
    'ragMetadata.lastReindexed': new Date(),
  });
  
  console.log(`\nâœ… Re-indexing complete!`);
  console.log(`  Success: ${successCount} chunks`);
  console.log(`  Failed: ${failCount} chunks`);
}

// Get sourceId from command line
const sourceId = process.argv[2];
if (!sourceId) {
  console.error('âŒ Usage: npx tsx scripts/reindex-document.ts <sourceId>');
  process.exit(1);
}

reindexDocument(sourceId)
  .then(() => process.exit(0))
  .catch(error => {
    console.error('âŒ Re-indexing failed:', error);
    process.exit(1);
  });
```

**Uso:**
```bash
npx tsx scripts/reindex-document.ts 8tjgUceVZW0A46QYYRfW
```

---

## ğŸ“‹ Action Items

### AHORA (Inmediato):
1. [ ] Verificar Vertex AI funciona (test simple)
2. [ ] Crear script de re-indexaciÃ³n
3. [ ] Re-indexar Cir32.pdf
4. [ ] Retry pregunta y verificar logs

### Si Vertex AI funciona:
- [ ] Re-indexar todos los documentos
- [ ] Subir threshold a 0.3
- [ ] Sistema RAG completamente funcional

### Si Vertex AI NO funciona:
- [ ] Investigar error especÃ­fico
- [ ] Fix API call
- [ ] Alternative: Usar OpenAI embeddings
- [ ] Re-test

---

## ğŸ“ Key Insight

**El problema NO es el flujo RAG, es la CALIDAD de los embeddings.**

Con embeddings semÃ¡nticos reales:
- Texto idÃ©ntico â†’ 95%+ similarity âœ…
- Texto similar â†’ 70-90% similarity âœ…
- Tema relacionado â†’ 50-70% similarity âœ…
- No relacionado â†’ <30% similarity âœ…

Con embeddings determinÃ­sticos:
- Texto idÃ©ntico â†’ 80-100% similarity âœ…
- Texto similar â†’ 5-15% similarity âŒ
- Tema relacionado â†’ 2-8% similarity âŒ
- No relacionado â†’ 0-2% similarity âŒ

**Threshold de 0.3 funciona con semÃ¡nticos, pero nunca con determinÃ­sticos.**

---

**Created:** 2025-10-20  
**Next Step:** Crear script de re-indexaciÃ³n y ejecutar  
**ETA:** 15-20 minutos para re-indexar y probar

