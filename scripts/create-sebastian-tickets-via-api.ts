/**
 * Create backlog tickets from Sebastian's feedback via API
 * Uses webapp API endpoints with authentication
 */

const SEBASTIAN_USER_ID = '114671162830729001607';
const COMPANY_ID = 'salfacorp';
const BASE_URL = 'http://localhost:3000';

interface TicketData {
  title: string;
  description: string;
  userStory: string;
  acceptanceCriteria: string[];
  type: string;
  category: string;
  priority: string;
  estimatedEffort: string;
  tags: string[];
  affectedUsers: number;
  estimatedCSATImpact: number;
  estimatedNPSImpact: number;
}

const tickets: TicketData[] = [
  // FB-001: S1 - Referencias no aparecen
  {
    title: '[S1] Referencias no aparecen en respuestas',
    description: `Usuario Sebastian reporta que el agente S1 (GESTION BODEGAS GPT - S001) no muestra referencias en sus respuestas.

**Observaci√≥n:**
- Probado en usuario admin Y usuario final
- Mismo comportamiento (no muestra referencias)
- El sistema de referencias funciona en M1, no en S1

**Impacto:**
- Usuario no puede verificar fuentes
- Reduce confianza en respuestas
- Imposible auditar informaci√≥n

**Hip√≥tesis:**
1. S1 no tiene context sources asignados
2. Context sources no est√°n activados (toggles)
3. Documentos subidos solo contienen referencias a otros docs no subidos`,
    userStory: 'Como usuario de S1, quiero ver referencias clickeables en las respuestas, para poder verificar las fuentes de informaci√≥n',
    acceptanceCriteria: [
      'S1 muestra referencias clickeables tipo [1], [2], [3]',
      'Referencias aparecen tanto en usuario admin como usuario final',
      'Panel de Referencias muestra fragmentos utilizados',
      'Click en referencia abre detalle del fragmento',
    ],
    type: 'bug',
    category: 'other',
    priority: 'high',
    estimatedEffort: 'm',
    tags: ['s1', 'referencias', 'rag', 'sebastian-feedback'],
    affectedUsers: 2,
    estimatedCSATImpact: 8,
    estimatedNPSImpact: 15,
  },
  
  // FB-002: M1 - Alucinaci√≥n de referencias [FIXED]
  {
    title: '[M1] AI inventa referencias que no existen (FIXED)',
    description: `Usuario Sebastian reporta que M1 usa referencias como [7] cuando solo hay 5 fragmentos.

**Observaci√≥n:**
- Pregunta: "¬øQu√© es un OGUC?"
- Respuesta incluye [7] en el texto
- Pero solo hay 5 fragmentos citados ([1] a [5])
- El AI est√° inventando el n√∫mero [7]

**Soluci√≥n Implementada (commit ce47110):**
- System prompt reforzado con reglas estrictas
- PROHIBIDO usar n√∫meros fuera del rango v√°lido
- Ejemplo expl√≠cito de n√∫mero inv√°lido

**Testing Requerido:**
- Manual: Pregunta "¬øQu√© es un OGUC?" en M1
- Verificar: Solo usa [1][2][3][4][5], NO [7]
- Confirmar con Sebastian que funciona

**Status:** ‚úÖ Fix implementado, pendiente testing usuario`,
    userStory: 'Como usuario de M1, quiero que las referencias sean solo a fragmentos que existen, para poder confiar en las citas',
    acceptanceCriteria: [
      'AI solo usa referencias que existen (ej: [1-5] si hay 5 fragmentos)',
      'NO aparecen referencias inventadas ([6], [7], etc.)',
      'Testing con pregunta "¬øQu√© es un OGUC?" pasa',
      'Sebastian confirma que funciona correctamente',
    ],
    type: 'bug',
    category: 'other',
    priority: 'critical',
    estimatedEffort: 's',
    tags: ['m1', 'referencias', 'alucinacion', 'rag', 'sebastian-feedback', 'fixed'],
    affectedUsers: 2,
    estimatedCSATImpact: 9,
    estimatedNPSImpact: 20,
  },
  
  // FB-003: M1 - Fragmentos basura RAG [FIXED]
  {
    title: '[M1] 80% de fragmentos RAG son basura (FIXED)',
    description: `Usuario Sebastian reporta que 4 de 5 fragmentos devueltos por RAG son irrelevantes.

**Observaci√≥n:**
Pregunta: "¬øQu√© es un OGUC?"
Fragmentos devueltos:
- ‚ùå Fragmento 1: "1. INTRODUCCI√ìN .............." (TOC)
- ‚ùå Fragmento 2: "1. INTRODUCCI√ìN .............." (TOC)
- ‚ùå Fragmento 3: "P√°gina 2 de 3" (4 tokens, n√∫mero de p√°gina)
- ‚ùå Fragmento 4: "1. INTRODUCCI√ìN .............." (TOC)
- ‚úÖ Fragmento 5: Contenido √∫til sobre OGUC

**Resultado:** Solo 1 de 5 √∫til (20% calidad)

**Soluci√≥n Implementada (commit ce47110):**
- Nueva funci√≥n filterGarbageChunks() en chunking.ts
- Filtra: headers TOC, n√∫meros de p√°gina, separadores, chunks <50 chars
- Integrado en pipeline de indexing (webapp + CLI)

**Requiere:**
- Re-indexar documentos existentes de M1
- Nuevos uploads autom√°ticamente filtrados

**Resultado Esperado:**
- De 20% √∫til ‚Üí 90% √∫til
- 4-5 de 5 fragmentos relevantes

**Status:** ‚úÖ Fix implementado, pendiente re-indexing + testing`,
    userStory: 'Como usuario de M1, quiero que los fragmentos RAG sean √∫tiles y relevantes, para obtener respuestas de calidad basadas en documentos',
    acceptanceCriteria: [
      'Fragmentos NO contienen headers TOC ("INTRODUCCI√ìN ...")',
      'Fragmentos NO contienen n√∫meros de p√°gina ("P√°gina X de Y")',
      'Fragmentos NO contienen solo separadores o puntos',
      'Al menos 80% de fragmentos devueltos son √∫tiles',
      'Pregunta "¬øQu√© es un OGUC?" devuelve 4-5 de 5 √∫tiles',
      'Sebastian confirma mejora en calidad',
    ],
    type: 'bug',
    category: 'other',
    priority: 'critical',
    estimatedEffort: 'm',
    tags: ['m1', 'rag', 'chunks', 'calidad', 'sebastian-feedback', 'fixed', 'requiere-reindex'],
    affectedUsers: 2,
    estimatedCSATImpact: 10,
    estimatedNPSImpact: 25,
  },
  
  // FB-004: M1 - Modal "Ver documento" no abre
  {
    title: '[M1] Modal "Ver documento original" no abre',
    description: `Usuario Sebastian reporta que el bot√≥n "Ver documento original" en referencias no funciona.

**Observaci√≥n:**
- Usuario hace click en referencia ‚Üí Panel de detalle se abre ‚úÖ
- Usuario hace click en "Ver documento original"
- ‚ùå Modal no se abre
- ‚ùå No pasa nada

**Impacto:**
- Feature prometida no funciona
- Usuario no puede ver contexto completo
- Experiencia incompleta

**Investigaci√≥n Requerida:**
- Verificar si modal est√° implementado
- Verificar event handler
- Verificar si es feature pendiente`,
    userStory: 'Como usuario, quiero ver el documento completo al hacer click en "Ver documento original", para entender el contexto completo del fragmento',
    acceptanceCriteria: [
      'Click en "Ver documento original" abre modal',
      'Modal muestra documento completo',
      'Modal tiene opci√≥n de cerrar (X o ESC)',
      'Modal muestra nombre del documento en header',
    ],
    type: 'bug',
    category: 'ui',
    priority: 'medium',
    estimatedEffort: 's',
    tags: ['m1', 'modal', 'ui', 'referencias', 'sebastian-feedback'],
    affectedUsers: 2,
    estimatedCSATImpact: 6,
    estimatedNPSImpact: 10,
  },
  
  // FB-005: S1 - AI solo menciona documentos
  {
    title: '[S1] AI menciona documentos pero no usa su contenido',
    description: `Usuario Sebastian reporta que S1 solo dice "consulta el documento X" en vez de dar la respuesta.

**Observaci√≥n:**
Pregunta 1: "¬øC√≥mo genero el informe de consumo de petr√≥leo?"
Pregunta 2: "Como Imprimir Resumen Consumo Petr√≥leo?"

Respuesta del AI:
"Seg√∫n el documento MAQ-LOG-CBO-I-002, debes consultar el instructivo MAQ-LOG-CBO-PP-009"

Pregunta 3: "Resume el documento MAQ-LOG-CBO-PP-009"
Respuesta: "El documento MAQ-LOG-CBO-PP-009 no se encuentra incluido"

**Root Cause:**
- Documento I-002 S√ç est√° en el sistema ‚úÖ
- Documento I-002 menciona documento PP-009 ‚úÖ
- Documento PP-009 NO est√° en el sistema ‚ùå
- Por eso AI solo puede decir "ve al documento PP-009"

**Soluci√≥n:**
- Subir documentos faltantes (PP-009, etc.)
- Verificar que todos los documentos referenciados est√©n disponibles
- Completar la cadena de documentaci√≥n`,
    userStory: 'Como usuario de S1, quiero que el AI use el contenido de los documentos para responder, no solo mencionar que existen otros documentos',
    acceptanceCriteria: [
      'AI responde con el contenido de documentos, no solo menciones',
      'Todos los documentos referenciados est√°n subidos al sistema',
      'Pregunta sobre procedimientos obtiene pasos concretos',
      'No dice "consulta el instructivo X" si X no est√° disponible',
    ],
    type: 'enhancement',
    category: 'other',
    priority: 'high',
    estimatedEffort: 'm',
    tags: ['s1', 'documentos', 'contenido', 'referencias-cruzadas', 'sebastian-feedback'],
    affectedUsers: 2,
    estimatedCSATImpact: 9,
    estimatedNPSImpact: 20,
  },
];

async function createTicketsViaAPI() {
  console.log('üé´ Creando tickets v√≠a API webapp...\n');
  console.log(`   Base URL: ${BASE_URL}`);
  console.log(`   Company: ${COMPANY_ID}`);
  console.log(`   Tickets a crear: ${tickets.length}\n`);
  
  const createdTickets = [];
  
  for (let i = 0; i < tickets.length; i++) {
    const ticket = tickets[i];
    
    try {
      console.log(`üìù [${i + 1}/${tickets.length}] Creando: ${ticket.title}`);
      
      const response = await fetch(`${BASE_URL}/api/backlog/create`, {
        method: 'POST',
        headers: {
          'Content-Type': 'application/json',
        },
        body: JSON.stringify({
          companyId: COMPANY_ID,
          userId: SEBASTIAN_USER_ID,
          ...ticket,
          feedbackSessionIds: ['sebastian-session-2025-10-28'],
          alignedOKRs: ['improve-agent-quality', 'reduce-hallucination'],
          okrImpactScore: 8,
          lane: 'next', // Start in roadmap lane
          status: 'ready',
        }),
      });
      
      if (!response.ok) {
        const errorText = await response.text();
        console.error(`   ‚ùå Error ${response.status}: ${errorText}\n`);
        continue;
      }
      
      const data = await response.json();
      console.log(`   ‚úÖ Creado con ID: ${data.id}`);
      console.log(`   Lane: next (Roadmap)`);
      console.log(`   Priority: ${ticket.priority}`);
      console.log();
      
      createdTickets.push({ id: data.id, ...ticket });
      
    } catch (error) {
      console.error(`   ‚ùå Error: ${error.message}\n`);
    }
  }
  
  console.log(`\nüéâ ${createdTickets.length} de ${tickets.length} tickets creados!\n`);
  
  if (createdTickets.length > 0) {
    console.log('üìä Resumen:');
    console.log(`   Critical: ${createdTickets.filter(t => t.priority === 'critical').length}`);
    console.log(`   High: ${createdTickets.filter(t => t.priority === 'high').length}`);
    console.log(`   Medium: ${createdTickets.filter(t => t.priority === 'medium').length}`);
    console.log();
    
    console.log('üîó Ver en Kanban Roadmap:');
    console.log(`   ${BASE_URL}/roadmap\n`);
    
    console.log('üìù Tickets creados:');
    createdTickets.forEach(t => {
      const fixedTag = t.tags.includes('fixed') ? ' ‚úÖ FIXED' : '';
      console.log(`   ‚Ä¢ ${t.title}${fixedTag}`);
    });
  }
}

createTicketsViaAPI();

