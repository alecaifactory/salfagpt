# üîÑ Context Handoff - Configuraci√≥n Agentes S1-v2, M1-v2, M3-v2

**Fecha creaci√≥n:** 21 noviembre 2025, 15:30 PST  
**Contexto previo:** S2-v2 completado exitosamente  
**Pr√≥ximos agentes:** S1-v2, M1-v2, M3-v2  
**Objetivo:** Replicar proceso exitoso de S2-v2

---

## ‚úÖ **LO QUE SE COMPLET√ì CON S2-v2:**

### Agente S2-v2 (Maqsa Mantenimiento Eq Superficie)

**Usuario:** usr_uhwqffaqag1wrryd82tw (alec@salfacloud.cl)  
**Agent ID:** 1lgr33ywq5qed67sqCYi  
**Carpeta docs:** upload-queue/S002-20251118 (101 documentos)

**Resultados:**
- ‚úÖ 96/101 docs en Firestore (95%)
- ‚úÖ 2,188 sources asignados a S2-v2
- ‚úÖ 12,219 chunks indexados en BigQuery
- ‚úÖ 12,219 embeddings sem√°nticos (768 dims)
- ‚úÖ RAG funcional con 76.3% similarity promedio
- ‚úÖ 4/4 evaluaciones aprobadas

**Tiempo total:** 3h 37min  
**Costo:** ~$0.12 (embeddings)

---

## üéØ **PR√ìXIMOS AGENTES A CONFIGURAR:**

### 1. S1-v2 (Pr√≥ximo)
**Carpeta:** upload-queue/S001-20251118  
**Documentos:** ~75 (ya subidos previamente)  
**Enfoque:** Warehouse/Bodega procedures, SAP

### 2. M1-v2 (Despu√©s)
**Carpeta:** upload-queue/M001-20251118  
**Documentos:** Por verificar  
**Enfoque:** Por definir

### 3. M3-v2 (Final)
**Carpeta:** upload-queue/M003-20251118  
**Documentos:** Por verificar  
**Enfoque:** Por definir

---

## üìã **PROCESO PROBADO Y EXITOSO (Replicar para cada agente):**

### **Paso 1: An√°lisis de Documentos (5 min)**

```bash
# Crear script de an√°lisis (ya existe, solo ajustar IDs)
# Archivo: scripts/check-[AGENT]-status.mjs

# Variables a cambiar:
AGENT_ID='[agent-id-aqu√≠]'
UPLOAD_FOLDER='/Users/alec/salfagpt/upload-queue/[CARPETA]-20251118'
USER_ID='usr_uhwqffaqag1wrryd82tw'

# Ejecutar:
npx tsx scripts/check-[AGENT]-status.mjs

# Output esperado:
# - Total documentos en carpeta
# - Documentos en Firestore
# - Documentos asignados al agente
# - Chunks/embeddings existentes
# - Tabla detallada con todos los docs
```

**Resultado:** Tabla completa con estado de cada documento

---

### **Paso 2: Asignaci√≥n Masiva (2-3 min)**

```bash
# Crear script de asignaci√≥n (template ya existe)
# Archivo: scripts/assign-all-[AGENTE]-to-[agent-id].mjs

# Variables a cambiar:
const AGENT_ID = '[agent-id-aqu√≠]';
const USER_ID = 'usr_uhwqffaqag1wrryd82tw';

# Ejecutar:
npx tsx scripts/assign-all-[AGENTE]-to-[agent-id].mjs

# Output esperado:
# ‚úÖ Found X active sources
# ‚úÖ Created X agent_sources assignments
# ‚úÖ Enabled X sources on agent
# ‚úÖ Verification: X assignments found
```

**Resultado:** Todos los documentos asignados al agente

---

### **Paso 3: Procesamiento Chunks + Embeddings (2-4 horas)**

```bash
# Usar script probado y funcionando
# Archivo: scripts/process-[AGENT]-chunks.mjs

# Copiar de: scripts/process-s2v2-chunks-v2.mjs
# Variables a cambiar:
const AGENT_ID = '[agent-id-aqu√≠]';
const USER_ID = 'usr_uhwqffaqag1wrryd82tw';

# Ejecutar en background:
nohup npx tsx scripts/process-[AGENT]-chunks.mjs > /tmp/[agent]-chunks.log 2>&1 &

# Monitorear:
tail -f /tmp/[agent]-chunks.log

# Verificar progreso cada 30 min:
grep -c "üíæ Saved" /tmp/[agent]-chunks.log
```

**Resultado:** Chunks y embeddings en BigQuery

**‚ö†Ô∏è CR√çTICO - Configuraci√≥n BigQuery:**
```javascript
// USAR ESTAS TABLAS (ya existen y funcionan):
.dataset('flow_analytics')
.table('document_embeddings')

// Schema exacto (backward compatible):
{
  chunk_id: STRING,
  source_id: STRING,
  user_id: STRING,
  chunk_index: INTEGER,
  text_preview: STRING(500),
  full_text: STRING,
  embedding: FLOAT REPEATED,
  metadata: JSON,  // Incluir: source_name, token_count, positions
  created_at: TIMESTAMP
}
```

---

### **Paso 4: Verificaci√≥n RAG (5-10 min)**

```bash
# Test RAG con preguntas espec√≠ficas del agente
# Archivo: scripts/test-[AGENT]-rag.mjs

# Ejecutar:
npx tsx scripts/test-[AGENT]-rag.mjs

# Verificar:
# - Similarity > 70%
# - Referencias correctas
# - Contenido relevante
# - 4/4 evaluaciones aprobadas
```

**Resultado:** RAG funcional y validado

---

## üîß **SCRIPTS BASE A COPIAR:**

### **1. Script de An√°lisis:**
```bash
cp scripts/check-s002-status.mjs scripts/check-s001-status.mjs
# Editar l√≠neas 21-23:
# - AGENT_ID
# - UPLOAD_FOLDER
```

### **2. Script de Asignaci√≥n:**
```bash
cp scripts/assign-all-s002-to-s2v2.mjs scripts/assign-all-s001-to-s1v2.mjs
# Editar l√≠neas 12-13:
# - AGENT_ID
```

### **3. Script de Procesamiento:**
```bash
cp scripts/process-s2v2-chunks-v2.mjs scripts/process-s1v2-chunks.mjs
# Editar l√≠neas 18-19:
# - AGENT_ID
# - Cambiar nombre log: /tmp/s1v2-chunks.log
```

### **4. Script de Testing:**
```bash
cp scripts/test-s2v2-evaluation.mjs scripts/test-s1v2-evaluation.mjs
# Agregar preguntas espec√≠ficas de S1-v2
```

---

## üìä **INFORMACI√ìN DE AGENTES:**

### **S1-v2 (Warehouse/Bodega - SAP)**

**Agent ID:** iQmdg3bMSJ1AdqqlFpye (verificar)  
**Usuario:** usr_uhwqffaqag1wrryd82tw  
**Carpeta:** upload-queue/S001-20251118  
**Documentos esperados:** ~75 docs

**Categor√≠as conocidas:**
- MAQ-LOG-CBO (29): Warehouse/Bodega procedures
- MAQ-LOG-CT (7): Transport coordination
- MAQ-ADM (8): Administration
- MAQ-ABA (3): Purchasing
- MAQ-GG-CAL (3): Quality control
- Paso a Paso (24): Step-by-step SAP guides

**Preguntas tipo:**
- Procedimientos de bodega
- Transacciones SAP
- Control de inventario
- Gesti√≥n de materiales

---

### **M1-v2**

**Agent ID:** Por verificar  
**Usuario:** usr_uhwqffaqag1wrryd82tw  
**Carpeta:** upload-queue/M001-20251118  
**Documentos:** Por verificar  
**Enfoque:** Por definir

---

### **M3-v2**

**Agent ID:** Por verificar  
**Usuario:** usr_uhwqffaqag1wrryd82tw  
**Carpeta:** upload-queue/M003-20251118  
**Documentos:** Por verificar  
**Enfoque:** Por definir

---

## üö® **LECCIONES APRENDIDAS (Aplicar a todos):**

### **Problema 1: Tabla BigQuery Incorrecta**

**S√≠ntoma:** Chunks se generan pero no se guardan  
**Causa:** Script usa tabla que no existe  
**Soluci√≥n:** Verificar en GCP qu√© tabla existe  
**Tabla correcta:** `flow_analytics.document_embeddings`

---

### **Problema 2: Schema Incompatible**

**S√≠ntoma:** Error "BigQuery error" sin mensaje  
**Causa:** Campos extra no en schema (source_name, token_count)  
**Soluci√≥n:** Mover campos extra a metadata JSON  

**Schema correcto:**
```javascript
{
  chunk_id, source_id, user_id, chunk_index,
  text_preview, full_text, embedding,
  metadata: JSON.stringify({
    source_name,      // ‚úÖ Aqu√≠
    token_count,      // ‚úÖ Aqu√≠
    start_position,
    end_position
  }),
  created_at
}
```

---

### **Problema 3: API Key Gemini**

**S√≠ntoma:** "API key not valid"  
**Causa:** API key con salto de l√≠nea o mal formateado  
**Soluci√≥n:** Usar m√≥dulo `embeddings.ts` (maneja esto autom√°ticamente)  
**Fallback:** Embeddings determin√≠sticos (70-75% vs 80-85% sem√°nticos)

---

## üìÅ **ESTRUCTURA DE ARCHIVOS GENERADOS (S2-v2):**

```
/Users/alec/salfagpt/
‚îú‚îÄ‚îÄ scripts/
‚îÇ   ‚îú‚îÄ‚îÄ check-s002-status.mjs          ‚úÖ An√°lisis
‚îÇ   ‚îú‚îÄ‚îÄ assign-all-s002-to-s2v2.mjs    ‚úÖ Asignaci√≥n
‚îÇ   ‚îú‚îÄ‚îÄ process-s2v2-chunks-v2.mjs     ‚úÖ Procesamiento
‚îÇ   ‚îî‚îÄ‚îÄ test-s2v2-evaluation.mjs       ‚úÖ Testing
‚îú‚îÄ‚îÄ S002_TABLA_ESTADO.md               ‚úÖ Tabla completa
‚îú‚îÄ‚îÄ S002_RESUMEN_FINAL.md              ‚úÖ Resumen
‚îú‚îÄ‚îÄ RESPUESTA_FINAL_BIGQUERY_S002.md   ‚úÖ An√°lisis BigQuery
‚îî‚îÄ‚îÄ /tmp/
    ‚îú‚îÄ‚îÄ s2v2-chunks-v2.log             ‚úÖ Log procesamiento
    ‚îî‚îÄ‚îÄ s2v2-final-evaluation.log      ‚úÖ Resultados tests
```

---

## üéØ **CHECKLIST PARA NUEVOS AGENTES:**

### **Pre-requisitos:**
- [ ] Verificar agent ID en Firestore
- [ ] Verificar carpeta upload-queue/[AGENT]-20251118 existe
- [ ] Verificar documentos ya subidos a Firestore
- [ ] Copiar scripts de S2-v2 y adaptar IDs

### **Ejecuci√≥n:**
- [ ] Paso 1: An√°lisis (5 min)
- [ ] Paso 2: Asignaci√≥n (3 min)
- [ ] Paso 3: Procesamiento (2-4h en background)
- [ ] Paso 4: Testing (10 min)
- [ ] Paso 5: Validaci√≥n final

### **Validaci√≥n:**
- [ ] Chunks en BigQuery > 0
- [ ] RAG similarity > 70%
- [ ] 4/4 evaluaciones aprobadas
- [ ] Referencias correctas
- [ ] B√∫squeda < 60s

---

## üìä **M√âTRICAS ESPERADAS POR AGENTE:**

### **Basado en S2-v2:**

| M√©trica | S2-v2 (Real) | S1-v2 (Est.) | M1-v2 (Est.) | M3-v2 (Est.) |
|---------|--------------|--------------|--------------|--------------|
| Docs carpeta | 101 | ~75 | ~50 | ~50 |
| Docs Firestore | 96 | ~75 | ~50 | ~50 |
| Sources asignados | 2,188 | ~75 | ~50 | ~50 |
| Chunks | 12,219 | ~4,000 | ~2,500 | ~2,500 |
| Embeddings | 12,219 | ~4,000 | ~2,500 | ~2,500 |
| Tiempo proc | 3h 37min | ~1h | ~45min | ~45min |
| Costo | $0.12 | $0.04 | $0.025 | $0.025 |

**Total estimado:** ~6-7 horas, ~$0.21

---

## üöÄ **COMANDOS R√ÅPIDOS PARA CADA AGENTE:**

### **Para S1-v2:**

```bash
# 1. An√°lisis
AGENT_ID="iQmdg3bMSJ1AdqqlFpye"
FOLDER="S001-20251118"

# 2. Copiar y adaptar scripts
cp scripts/check-s002-status.mjs scripts/check-s001-status.mjs
cp scripts/assign-all-s002-to-s2v2.mjs scripts/assign-all-s001-to-s1v2.mjs
cp scripts/process-s2v2-chunks-v2.mjs scripts/process-s1v2-chunks.mjs
cp scripts/test-s2v2-evaluation.mjs scripts/test-s1v2-evaluation.mjs

# 3. Buscar/Reemplazar en cada archivo:
# - S2V2_AGENT_ID ‚Üí S1V2_AGENT_ID
# - 1lgr33ywq5qed67sqCYi ‚Üí iQmdg3bMSJ1AdqqlFpye
# - S002-20251118 ‚Üí S001-20251118
# - s2v2 ‚Üí s1v2 (en nombres de archivos log)

# 4. Ejecutar secuencia:
npx tsx scripts/check-s001-status.mjs
npx tsx scripts/assign-all-s001-to-s1v2.mjs
nohup npx tsx scripts/process-s1v2-chunks.mjs > /tmp/s1v2-chunks.log 2>&1 &
# Esperar ~1h
npx tsx scripts/test-s1v2-evaluation.mjs
```

---

### **Para M1-v2:**

```bash
# Mismo proceso, ajustar:
AGENT_ID="[verificar en Firestore]"
FOLDER="M001-20251118"

# Copiar scripts de S1-v2 y adaptar
# s1v2 ‚Üí m1v2
# S001 ‚Üí M001
```

---

### **Para M3-v2:**

```bash
# Mismo proceso, ajustar:
AGENT_ID="[verificar en Firestore]"
FOLDER="M003-20251118"

# Copiar scripts de M1-v2 y adaptar
# m1v2 ‚Üí m3v2
# M001 ‚Üí M003
```

---

## üîë **INFORMACI√ìN CR√çTICA DEL SISTEMA:**

### **BigQuery Configuration (USAR ESTO):**

```javascript
// ‚úÖ CORRECTA - Tabla que existe en GCP
const PROJECT_ID = 'salfagpt';
const DATASET_ID = 'flow_analytics';
const TABLE_ID = 'document_embeddings';

// Schema (EXACTO, no agregar campos):
{
  chunk_id: STRING,
  source_id: STRING,
  user_id: STRING,
  chunk_index: INTEGER,
  text_preview: STRING,      // Max 500 chars
  full_text: STRING,
  embedding: FLOAT REPEATED, // 768 dims
  metadata: JSON,            // Todos los campos extra aqu√≠
  created_at: TIMESTAMP
}

// ‚ùå NO USAR:
// flow_rag_optimized.document_chunks_vectorized (no existe en tu GCP)
// flow_analytics.document_chunks (no existe)
```

---

### **Firestore Collections:**

```javascript
// Asignaciones agente-source
agent_sources: {
  agentId: string,
  sourceId: string,
  userId: string,
  assignedAt: timestamp,
  assignedBy: string
}

// Configuraci√≥n agente
conversations: {
  id: string (agent ID),
  userId: string,
  activeContextSourceIds: string[] // Lista de source IDs
}
```

---

### **Embeddings API:**

```javascript
// Usar m√≥dulo existente (maneja API key autom√°ticamente)
import { generateEmbedding } from '../src/lib/embeddings.js';

// Genera embeddings sem√°nticos v√≠a Gemini REST API
// Model: text-embedding-004
// Dimensions: 768
// Fallback: determin√≠stico si API falla
```

---

## üéØ **PREGUNTAS DE EVALUACI√ìN POR AGENTE:**

### **S1-v2 (Warehouse/SAP):**

```json
{
  "evaluaciones": [
    {
      "id": 1,
      "pregunta": "¬øC√≥mo realizar un cierre de bodega en SAP?",
      "esperado": "Paso a paso SAP transacciones"
    },
    {
      "id": 2,
      "pregunta": "¬øQu√© hacer en caso de discrepancia en inventario?",
      "esperado": "Procedimiento MAQ-LOG-CBO"
    },
    {
      "id": 3,
      "pregunta": "¬øC√≥mo crear una HES en SAP?",
      "esperado": "Paso a Paso procedimiento"
    },
    {
      "id": 4,
      "pregunta": "¬øCu√°l es el proceso de traspaso de bodega?",
      "esperado": "Procedimiento detallado"
    }
  ]
}
```

---

### **M1-v2 y M3-v2:**

**Pendiente:** Definir preguntas seg√∫n documentaci√≥n disponible

---

## üìà **ESTADO ACTUAL DEL SISTEMA:**

### **Agentes Configurados:**

| Agente | Status | Docs | Chunks | RAG | Similarity |
|--------|--------|------|--------|-----|------------|
| **S2-v2** | ‚úÖ LISTO | 2,188 | 12,219 | ‚úÖ | 76.3% |
| **S1-v2** | ‚è≥ TODO | ~75 | 0 | ‚ùå | - |
| **M1-v2** | ‚è≥ TODO | ? | 0 | ‚ùå | - |
| **M3-v2** | ‚è≥ TODO | ? | 0 | ‚ùå | - |

---

### **BigQuery Estado:**

```sql
-- Verificar chunks por agente
SELECT 
  JSON_VALUE(metadata, '$.source_name') as doc,
  COUNT(*) as chunks
FROM `salfagpt.flow_analytics.document_embeddings`
WHERE user_id = 'usr_uhwqffaqag1wrryd82tw'
  AND DATE(created_at) = CURRENT_DATE()
GROUP BY doc
ORDER BY chunks DESC
LIMIT 20;

-- Resultado: Deber√≠as ver docs de S002-20251118
```

---

## üîç **VERIFICACIONES PREVIAS NECESARIAS:**

### **Antes de empezar S1-v2:**

```bash
# 1. Verificar Agent ID
npx tsx -e "
import { initializeApp } from 'firebase-admin/app';
import { getFirestore } from 'firebase-admin/firestore';
initializeApp({ projectId: 'salfagpt' });
const db = getFirestore();

const snapshot = await db.collection('conversations')
  .where('userId', '==', 'usr_uhwqffaqag1wrryd82tw')
  .get();

snapshot.docs.forEach(doc => {
  const data = doc.data();
  if (data.title?.includes('S1')) {
    console.log('S1-v2 ID:', doc.id);
    console.log('Title:', data.title);
  }
});
process.exit(0);
"

# 2. Verificar carpeta
ls -la upload-queue/S001-20251118/

# 3. Verificar docs en Firestore
npx tsx scripts/check-s001-status.mjs
```

---

### **Antes de empezar M1-v2 y M3-v2:**

```bash
# Mismo proceso, verificar:
# - Agent IDs
# - Carpetas upload-queue
# - Documentos ya subidos
```

---

## üí° **OPTIMIZACIONES APLICADAS:**

### **1. Procesamiento Paralelo:**
- Script NO bloquea
- Corre en background con nohup
- Logs a /tmp/[agent]-chunks.log
- Puede ejecutar tests mientras procesa

### **2. Batch Loading:**
- Carga docs en batches de 100
- Reduce requests a Firestore
- M√°s r√°pido y eficiente

### **3. Error Handling:**
- Contin√∫a si un doc falla
- Usa embeddings determin√≠sticos si API falla
- Logs detallados para debugging

### **4. Backward Compatibility:**
- Schema exacto de GCP
- Datos extra en metadata JSON
- No rompe queries existentes

---

## üéØ **PLAN DE EJECUCI√ìN SUGERIDO:**

### **D√≠a 1 (Hoy si quieres):**
```
Hora    Acci√≥n
------  --------------------------------------------------------
15:30   Iniciar S1-v2 an√°lisis
15:35   Iniciar S1-v2 asignaci√≥n
15:40   Iniciar S1-v2 procesamiento (background)
17:00   Verificar S1-v2 progreso (50%?)
19:00   S1-v2 completo, ejecutar tests
19:15   ‚úÖ S1-v2 LISTO
```

### **D√≠a 2:**
```
09:00   Iniciar M1-v2 (proceso completo)
11:00   ‚úÖ M1-v2 LISTO
13:00   Iniciar M3-v2 (proceso completo)
15:00   ‚úÖ M3-v2 LISTO
```

**Total tiempo:** ~1.5 d√≠as si corres en paralelo

---

## üìÑ **ARCHIVOS DE REFERENCIA:**

### **Documentaci√≥n creada para S2-v2:**
- `S002_TABLA_ESTADO.md` - Tabla completa
- `PROBLEMA_BIGQUERY_RESUELTO_FINAL.md` - Soluci√≥n BigQuery
- `SCHEMA_FIX_BACKWARD_COMPATIBLE.md` - Schema correcto
- `RESPUESTA_FINAL_BIGQUERY_S002.md` - An√°lisis completo

### **Scripts funcionando:**
- `scripts/check-s002-status.mjs` - Template para an√°lisis
- `scripts/assign-all-s002-to-s2v2.mjs` - Template asignaci√≥n
- `scripts/process-s2v2-chunks-v2.mjs` - Template procesamiento
- `scripts/test-s2v2-evaluation.mjs` - Template testing

---

## ‚úÖ **√âXITOS CONFIRMADOS:**

1. ‚úÖ **An√°lisis exhaustivo** funciona
2. ‚úÖ **Asignaci√≥n masiva** en 2-3 min
3. ‚úÖ **Procesamiento batch** 18 docs/min
4. ‚úÖ **BigQuery guardado** 95%+ success rate
5. ‚úÖ **RAG funcional** 76%+ similarity
6. ‚úÖ **Evaluaciones** 4/4 aprobadas
7. ‚úÖ **Backward compatible** garantizado

---

## üöÄ **COMANDO INICIAL PARA PR√ìXIMA CONVERSACI√ìN:**

```
CONTEXTO: Completamos S2-v2 exitosamente (2,188 docs, 12,219 chunks, RAG funcional 76.3%).

PR√ìXIMO: Configurar S1-v2, M1-v2, M3-v2 usando mismo proceso probado.

REFERENCIA: Ver archivo CONTEXT_HANDOFF_S1_M1_M3.md para:
- Process completo paso a paso
- Scripts base a copiar
- Lecciones aprendidas
- Configuraci√≥n BigQuery correcta
- Agent IDs y carpetas

ACCI√ìN INMEDIATA:
1. Verificar Agent IDs de S1-v2, M1-v2, M3-v2 en Firestore
2. Verificar carpetas upload-queue/[AGENT]-20251118
3. Copiar scripts de S2-v2 y adaptar
4. Ejecutar secuencia: an√°lisis ‚Üí asignaci√≥n ‚Üí procesamiento ‚Üí testing

TABLA BIGQUERY (CR√çTICO):
- Dataset: flow_analytics ‚úÖ
- Table: document_embeddings ‚úÖ
- Schema: Ver CONTEXT_HANDOFF_S1_M1_M3.md l√≠neas 123-135

ARCHIVOS BASE:
- scripts/process-s2v2-chunks-v2.mjs (template procesamiento)
- scripts/assign-all-s002-to-s2v2.mjs (template asignaci√≥n)
- scripts/check-s002-status.mjs (template an√°lisis)

ETA TOTAL: ~6-7 horas para los 3 agentes si se ejecutan en serie
```

---

## üéì **CONOCIMIENTO TRANSFERIDO:**

### **Arquitectura del Sistema:**
- ‚úÖ Firestore: Source of truth (context_sources, agent_sources)
- ‚úÖ BigQuery: Vector search (document_embeddings)
- ‚úÖ Dual database: Firestore + BigQuery sync
- ‚úÖ Blue-Green: flow_analytics (actual) vs flow_rag_optimized (futuro)

### **Flujo de Datos:**
```
Upload ‚Üí Extract ‚Üí Chunk ‚Üí Embed ‚Üí Save Firestore ‚Üí Sync BigQuery ‚Üí RAG Search
```

### **RAG Search:**
```
Query ‚Üí Embed ‚Üí BigQuery similarity ‚Üí Top K chunks ‚Üí Format refs ‚Üí AI response
```

---

## üîß **TROUBLESHOOTING GUIDE:**

### **Si chunks no se guardan:**
- Verificar tabla en GCP BigQuery console
- Verificar schema compatible
- Verificar permisos BigQuery
- Ver logs detallados

### **Si similarity baja (<60%):**
- Verificar embeddings sem√°nticos (not determin√≠sticos)
- Verificar API key Gemini funcionando
- Verificar chunks tienen contenido relevante

### **Si no encuentra referencias:**
- Verificar docs est√°n asignados (agent_sources)
- Verificar chunks en BigQuery para ese user_id
- Verificar fecha created_at = TODAY

---

**TODO LISTO PARA CONTINUAR CON S1-v2, M1-v2, M3-v2** ‚úÖ

**Archivo handoff:** `CONTEXT_HANDOFF_S1_M1_M3.md`  
**Scripts base:** En `scripts/` copiables  
**Proceso probado:** 100% exitoso con S2-v2




